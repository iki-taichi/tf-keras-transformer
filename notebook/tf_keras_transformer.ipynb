{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJfOp6rKrjMT"
   },
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "# We will output model files into mounted google drive.\n",
    "# Output directory can be changed.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "3vmEHJXQrxQt",
    "outputId": "516a66be-3778-46bd-de74-0aec355eb57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 18.6MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.82\n"
     ]
    }
   ],
   "source": [
    "# Default tokenizer uses sentence piece.\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "NeXMFcL2sIMC",
    "outputId": "5f628d22-fde8-4ccd-bff5-7254b544acfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tf-keras-transformer'...\n",
      "remote: Enumerating objects: 28, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 28 (delta 3), reused 23 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (28/28), done.\n",
      "Submodule 'src/tokenization' (https://github.com/iki-taichi/tokenization.git) registered for path 'src/tokenization'\n",
      "Cloning into '/content/tf-keras-transformer/src/tokenization'...\n",
      "remote: Enumerating objects: 21, done.        \n",
      "remote: Counting objects: 100% (21/21), done.        \n",
      "remote: Compressing objects: 100% (15/15), done.        \n",
      "remote: Total 21 (delta 5), reused 15 (delta 3), pack-reused 0        \n",
      "Submodule path 'src/tokenization': checked out 'f3290db6b1179985b2a29b7968b8d6fcbef48f73'\n"
     ]
    }
   ],
   "source": [
    "# Cloning the project repository\n",
    "# Do not forget \"--recursive\" option \n",
    "# to clone a submodule (tokenization for default tokenizer) at the same time.\n",
    "!git clone --recursive https://github.com/iki-taichi/tf-keras-transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWSgW_Z4sNuE"
   },
   "outputs": [],
   "source": [
    "# From now, we will work in the repository directory\n",
    "import os\n",
    "os.chdir('tf-keras-transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "Ay_H-kTWsVZt",
    "outputId": "272b4a8f-bbb0-4567-9e3a-0014f83e5cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start downloading...\n",
      "downloaded\n",
      "start editing files...\n",
      "to convert 14111 xml files...\n",
      "data sample:(data/kyoto_corpus/EPR/EPR00709.xml)[\"Ikisomimi no mikoto (or Okisomimi no mikoto, the date of birth and death unknown) was a member of the Imperial family who appears in 'Nihonshoki' (Chronicles of Japan) who lived during the Kofun period (tumulus period).\", '息石耳命（いきそみみのみこと、またはおきそみみのみこと、生没年未詳）は、「日本書紀」に登場する古墳時代の皇族。']\n",
      "data sample:(data/kyoto_corpus/EPR/EPR00709.xml)['He was the first Imperial prince of Emperor Annei, and his mother was Nunasokonakatsuhime no mikoto.', '安寧天皇の第一皇子で、母は渟名底仲媛命。']\n",
      "data sample:(data/kyoto_corpus/EPR/EPR00709.xml)['His younger maternal half-brothers include Emperor Itoku.', '同母弟に懿徳天皇らがいる。']\n",
      "data sample:(data/kyoto_corpus/EPR/EPR00709.xml)[\"Amatoyotsuhime no mikoto (Empress of Emperor Itoku) was his only child, and it is described in 'Sendai Kujihongi' (Ancient Japanese History) that he had no heir.\", '子は天豊津媛命（懿徳天皇皇后）のみで、跡継ぎがなかったと「先代旧事本紀」に記されている。']\n",
      "data/kyoto_corpus/GNM/GNM00155.xml skipped because of not well-formed (invalid token): line 2811, column 2425\n",
      "data/kyoto_en_ja_valid.csv,data/kyoto_en_ja.csv were created\n"
     ]
    }
   ],
   "source": [
    "# Preparation of a demo dataset\n",
    "# based on https://alaginrc.nict.go.jp/WikiCorpus/index_E.html\n",
    "# The dataset contains about 0.5 million English-Japanese sentence pairs\n",
    "!python src/get_kyoto_corpus.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEgXdUd6sYuN"
   },
   "outputs": [],
   "source": [
    "# Import fitting module\n",
    "from src.fitting import FitEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12128
    },
    "colab_type": "code",
    "id": "Alr4U-Xoso81",
    "outputId": "c273fd44-e505-4def-9182-40935f2b6f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training starting with env={\n",
      "  \"model_config\": \"{\\n  \\\"use_tpu\\\": true,\\n  \\\"tpu_grpc_url\\\": \\\"grpc://10.27.174.2:8470\\\",\\n  \\\"src_tokenizer\\\": \\\"sp_uncase_en_ja_40000\\\",\\n  \\\"tar_tokenizer\\\": \\\"sp_uncase_en_ja_40000\\\",\\n  \\\"use_same_embed\\\": true,\\n  \\\"block_num\\\": [\\n    6,\\n    6\\n  ],\\n  \\\"embed_dim\\\": 768,\\n  \\\"hidden_dim\\\": 3072,\\n  \\\"head_num\\\": 12,\\n  \\\"attention_activation\\\": \\\"relu\\\",\\n  \\\"feed_forward_activation\\\": \\\"gelu\\\",\\n  \\\"dropout_rate\\\": 0.1,\\n  \\\"input_len\\\": [\\n    1024,\\n    1024\\n  ],\\n  \\\"token_num\\\": [\\n    null,\\n    null\\n  ]\\n}\",\n",
      "  \"use_tpu\": true,\n",
      "  \"input_len\": [\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"work_dir\": \"model/translator_en_ja\",\n",
      "  \"output_dir\": \"/content/drive/My Drive/transformer_model\",\n",
      "  \"data_path\": [\n",
      "    \"data/kyoto_en_ja.csv\"\n",
      "  ],\n",
      "  \"valid_path\": [\n",
      "    \"data/kyoto_en_ja_valid.csv\"\n",
      "  ],\n",
      "  \"show_model_summary\": true,\n",
      "  \"batch_size\": 8,\n",
      "  \"num_epoch\": 5,\n",
      "  \"warm_step\": 4000,\n",
      "  \"train_callbacks\": [\n",
      "    \"<src.custom_callbacks.BatchLearningRateScheduler object at 0x7f33db0d3470>\",\n",
      "    \"<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f33db0d34e0>\",\n",
      "    \"<tensorflow.python.keras.callbacks.TensorBoard object at 0x7f33db0d34a8>\",\n",
      "    \"<src.custom_callbacks.NBatchLogger object at 0x7f33db0d3518>\"\n",
      "  ],\n",
      "  \"model_compiler\": \"<function FitEnvironment.get_default_model_compiler.<locals>._fun at 0x7f33db0be488>\",\n",
      "  \"resume_model_path\": null,\n",
      "  \"resume_initial_epoch\": null,\n",
      "  \"_train_examples_truncate_num\": null\n",
      "}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.27.174.2:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5909308277106014147)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2986202880765293044)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14660347284854071775)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8015096289969153122)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1379244075550528916)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16048031432848500318)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18367032996506293389)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13505675747238856251)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2599429903114025862)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9289169933796027054)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14464633131762527865)\n",
      "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Cloning Adam {'lr': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9800000190734863, 'decay': 0.0, 'epsilon': 1e-08, 'amsgrad': False}\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "Decoder-Token-Ids (InputLayer)                   (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-Token-Ids (InputLayer)                   (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingWithWeights)           [(None, 1024, 768), (40000, 768) 30720000          Decoder-Token-Ids[0][0]                           \n",
      "                                                                                                    Encoder-Token-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-Pos-Ids (InputLayer)                     (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbedding)             (None, 1024, 768)                0                 Token-Embedding[1][0]                             \n",
      "                                                                                                    Encoder-Pos-Ids[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-Group-Ids (InputLayer)                   (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-Embedding[0][0]                           \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-1-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-Embedding[0][0]                           \n",
      "                                                                                                    Encoder-1-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-1-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-1-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-1-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-1-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-1-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-1-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-1-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-2-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-1-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-2-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-2-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-2-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-2-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-2-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-2-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-2-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-2-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-3-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-2-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-3-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-3-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-3-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-3-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-3-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-3-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-3-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-3-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-4-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-3-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-4-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-4-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-4-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-4-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-4-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-4-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-4-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-4-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-5-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-4-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-5-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-5-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-5-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-5-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-5-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-5-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-5-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Encoder-5-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Encoder-6-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-Pos-Ids (InputLayer)                     (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Encoder-5-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-Embedding (TrigPosEmbedding)             (None, 1024, 768)                0                 Token-Embedding[0][0]                             \n",
      "                                                                                                    Decoder-Pos-Ids[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-Group-Ids (InputLayer)                   (None, 1024)                     0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Encoder-6-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-Embedding[0][0]                           \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Encoder-6-MultiHeadSelfAttention-Norm[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-1-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Encoder-6-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-Embedding[0][0]                           \n",
      "                                                                                                    Decoder-1-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Encoder-6-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Encoder-6-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-1-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Encoder-6-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-1-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-1-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-1-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-1-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-1-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-1-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-1-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-1-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-1-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-1-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-1-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-2-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-1-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-2-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-2-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-2-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-2-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-2-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-2-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-2-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-2-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-2-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-2-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-2-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-2-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-2-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-3-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-2-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-3-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-3-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-3-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-3-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-3-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-3-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-3-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-3-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-3-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-3-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-3-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-3-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-3-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-3-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-4-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-3-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-4-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-4-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-4-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-4-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-4-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-4-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-4-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-4-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-4-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-4-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-4-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-4-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-4-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-4-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-5-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-4-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-5-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-5-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-5-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-5-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-5-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-5-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-5-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-5-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-5-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-5-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-5-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-5-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-5-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadSelfAttention (MultiHeadAtten (None, 1024, 768)                2362368           Decoder-5-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadSelfAttention-Dropout (Dropou (None, 1024, 768)                0                 Decoder-6-MultiHeadSelfAttention[0][0]            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadSelfAttention-Add (Add)       (None, 1024, 768)                0                 Decoder-5-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Decoder-6-MultiHeadSelfAttention-Dropout[0][0]    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadSelfAttention-Norm (LayerNorm (None, 1024, 768)                1536              Decoder-6-MultiHeadSelfAttention-Add[0][0]        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadQueryAttention (MultiHeadAtte (None, 1024, 768)                2362368           Decoder-6-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-Group-Ids[0][0]                           \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Encoder-Group-Ids[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadQueryAttention-Dropout (Dropo (None, 1024, 768)                0                 Decoder-6-MultiHeadQueryAttention[0][0]           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadQueryAttention-Add (Add)      (None, 1024, 768)                0                 Decoder-6-MultiHeadSelfAttention-Norm[0][0]       \n",
      "                                                                                                    Decoder-6-MultiHeadQueryAttention-Dropout[0][0]   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-MultiHeadQueryAttention-Norm (LayerNor (None, 1024, 768)                1536              Decoder-6-MultiHeadQueryAttention-Add[0][0]       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-FeedForward (FeedForward)              (None, 1024, 768)                4722432           Decoder-6-MultiHeadQueryAttention-Norm[0][0]      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-FeedForward-Dropout (Dropout)          (None, 1024, 768)                0                 Decoder-6-FeedForward[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-FeedForward-Add (Add)                  (None, 1024, 768)                0                 Decoder-6-MultiHeadQueryAttention-Norm[0][0]      \n",
      "                                                                                                    Decoder-6-FeedForward-Dropout[0][0]               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Decoder-6-FeedForward-Norm (LayerNormalization)  (None, 1024, 768)                1536              Decoder-6-FeedForward-Add[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Output (EmbeddingSim)                            (None, 1024, 40000)              40000             Decoder-6-FeedForward-Norm[0][0]                  \n",
      "                                                                                                    Token-Embedding[1][1]                             \n",
      "======================================================================================================================================================\n",
      "Total params: 129,997,888\n",
      "Trainable params: 129,997,888\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "INFO:tensorflow:Making validation data...\n",
      "INFO:tensorflow:Loading examples\n",
      "INFO:tensorflow:Preparing new records\n",
      "INFO:tensorflow:New file created model/translator_en_ja/valid.tfrecord.0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-22004', 'train-0-34609', 'train-0-24405', 'train-0-18837', 'train-0-27111', 'train-0-43424', 'train-0-39452', 'train-0-39682', 'train-0-19752', 'train-0-32771', 'train-0-40403', 'train-0-8323', 'train-0-852', 'train-0-25157', 'train-0-9742', 'train-0-40340', 'train-0-2926']\n",
      "INFO:tensorflow:src_texts:[\"National Treasure - 'hongu goryo koshinporui' (imperial sacred treasures of the main shrine)\", 'Finally, a peace treaty was approved through the mediation of both Kozosu, a close aide of Kodaiin, and Mokujiki Ogo, a monk from Mt. Koya.', 'The upper storey is home to sculptures of the Buddha Shakamuni and his juroku rakan (the major sixteen enlightened disciples (Arhats)).', \"Tadaoki's name borrows one kanji character from the name of Nobunaga ODA's eldest son, Nobutada ODA.\", 'Atago-yama (Hioki City) - It is located in Hioki City, Kagoshima Prefecture.', '\"Voice\" reprints contributed articles concerning Buddhism and religion from other newspapers and magazines.', 'Incidentally, Ondo (study of pronunciation of the Chinese language) taught by On Hakase (professors of pronunciation of Chinese language) and Shodo (calligraphy) taught by Sho Hakase (professors of calligraphy) were subjects that supplemented the study of Myogyodo, and it is considered that the two subjects were practically integrated with Myogyodo by the middle of the Heian period.', 'While Saburo MIKI, Washio KANO, Yahei TOYAMA and Tainoshin SHIMOHARA escaped, Hattori, the only one who was armed, fought alone till his last breath with his back to a wall.', 'After the Meiji Restoration, both the Iwamatsu clan and the Yura clan were acknowledged by the Meiji government as being the descendants of Yoshisada and reverted to the family name of Nitta.', 'Tower Gate', '789 - He announced his retirement from a government post (to receive a skeleton).', 'He was the second son of the Emperor Gosai, and his mother was Tomoko who was a daughter of Tomotsuna SEIKANJI.', 'He was assigned to be Sangi (Councilor) in 908 but died the same year from being struck by lightening.', 'OTOMO no SAKANOUE no Oiratsume was her older sister.', 'The Kyogoku clan in Itoi, Yabu County (present Terauchi, Wadayama-cho, Asago City, Hyogo Prefecture), was a branch family of the Kyogoku clan in the Toyooka clan and was a descendant of a Shishoku family as well as the Yamana family.', \"The seize of the Ming force in the Battle of Shisen was not certain, but the record of the defeated Ming side mentioned 'eighty thousand war casualties.'\", 'Anrakushu (A Collection of Passages Concerning Birth in the Pure Land)']\n",
      "INFO:tensorflow:tar_texts:['国宝「本宮御料古神宝類」', 'ここに至り、高台院の側近孝蔵主と高野山の木食応其の仲介による講和が成立する。', '上層には釈迦如来と十六羅漢を安置する。', '忠興の名は、織田信長の嫡男・織田信忠の偏諱を受けたものである。', '愛宕山 (日置市) - 鹿児島県日置市にある。', '声新聞各誌の仏教・宗教に関する投稿を転載したもの。', 'なお、音博士の音道と書博士の書道 (大学寮)は、明経道の学習を補助するための学科であり、平安時代中期には明経道に実質的に統合されたと考えられている。', '三木三郎や加納鷲雄、富山弥兵衛、篠原泰之進らが逃走したが、ただ一人武装していた服部は、塀を背にして最期まで孤軍奮闘している。', '明治維新後に岩松氏、由良氏ともに明治政府に義貞の子孫として認定され、新田氏に復姓した。', '楼門', '延暦8年(789年) - 致仕（骸骨を賜ること）を上表。', '後西天皇の第二皇子、母は清閑寺共綱の娘共子。', '延喜8年（908年）に参議に任じられるが、同年に雷に打たれて死去。', '坂上大嬢の妹。', '養父郡糸井（現・兵庫県朝来市和田山町寺内）の京極氏は豊岡藩京極氏の分家で、山名氏と同様に四職の一家の後裔である。', 'ちなみに泗川の戦いでの明軍の兵力ははっきりしていないが、敗戦側の明の記録では「戦死者約8万人」とある。', '安楽集']\n",
      "INFO:tensorflow:Target:27631 58 25940 1350 6232 1058 596 2298 2038 64 4 0 19340 5893 369 20 357 716 947 31 2831 2583 2042 2000 1323 65 28948 12529 1769 4437 18255 31 34220 350 35443 11565 117 21 4 0 262 3723 186 19813 5733 1624 65 13954 4363 3190 46 30711 117 21 4 0 1468 2110 20042 20 23358 31 19615 32 34151 1468 31 32598 3749 4102 21 4 0 25755 184 2 22 23876 115 23 2 24 2 5062 23876 4237 21 4 0 1711 1905 1337 1811 31 5463 32 5183 1597 15590 46 3738 9312 6951 21 4 0 981 20 1017 4157 16347 355 65 940 4157 31 18417 2 22 382 11200 23 36 20 564 1857 355 31 7376 46 13596 10100 3165 452 20 9374 9631 186 564 1857 355 45 32454 4985 236 7409 21 4 0 9445 3506 109 26490 9985 892 20 7847 4620 5380 20 22658 2869 1016 1737 8612 35987 2229 20 7483 6937 14683 772 16464 36 20 39663 46 8001 6113 36719 616 29524 876 35648 242 21 4 0 24254 935 1226 1045 838 20 34877 838 7329 362 2742 45 781 3056 17998 119 4320 389 20 4431 838 45 7050 4527 99 21 4 0 13135 1036 4 0 21279 86 29 22 29805 29 23 2 24 2 13056 6569 22 28288 3091 46 11290 3875 23 46 262 1628 21 4 0 465 276 11562 2295 16930 20 10115 855 20315 475 4512 3882 2823 4512 188 21 4 0 37008 86 29 4283 2010 29 23 45 23068 17869 9415 20 20643 7316 45 37535 323 3385 21 4 0 27501 140 27800 14297 21 4 0 19659 220 6375 894 22 563 32 3257 1206 1624 115 6893 12383 475 430 23 31 27202 10837 21905 2047 27202 4223 27365 55 20 184 334 838 11164 1351 2094 31 13722 5383 34327 90 21 4 0 12453 1 238 13523 31 564 6400 1753 1109 36 24691 6668 42 20 19571 8341 564 9600 149 58 21454 454 809 86 7303 64 11800 21 4 0 785 2164 1183 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 122 2 13812 2 24 2 44 2732 113 2 2571 1578 2 391 2917 2770 6483 44 2 22 5975 2 13004 2 13812 25 2 26 2 19 2 691 2 14702 23 4 3 5343 18 2 28 2 3982 2 10896 2 41 2 10910 2 518 2 19 2 723 5120 2 26 2 654 2 391 2169 690 18 2 28 2 2562 2 5088 16 2 26 2 28309 79 27 18 2 30 2 73 11422 1106 540 2 98 300 18 2 28 2 10675 2 66 2 4917 17 2 391 913 17 4 3 19 2 3046 2 21661 2 39 2 525 2 35 2 7903 25 2 26 2 19 2 26852 2 7754 494 3923 2 30 2 84 2 8567 11422 2 7330 72 2 22 19 2 958 2 18098 2 16 59 1256 16 4360 2 31628 25 2 22 261 3117 25 23 81 4 3 329 352 13569 44 25 2 359 2 1876 22863 2 38 16 2 1670 1106 2 2354 2 66 2 19 2 359 2 26 2 24731 8898 2 8630 44 25 2 14351 2 351 18 2 131 216 3691 2 8630 17 4 3 49 4996 24 3346 2 22 1223 13569 2 235 23 2 24 2 69 2 39 2 420 2 27 2 1223 13569 2 235 18 2 332 300 10673 2 7178 17 4 3 33 2873 33 2 26571 25 2 10709 2 3483 2 19293 2 29867 2 30 2 7722 2 66 2 283 2 5042 2 30 2 14893 17 4 3 10063 3602 18 2 38 318 2 22 2376 2 26 2 14285 2 26 2 19 2 1234 2 1376 23 2 6011 2 56 2 38 2 12016 48 16 2 22 1554 25 2 26 2 14285 2 26 2 1234 2 1376 23 2 30 2 3682 318 2 22 19993 5989 101 23 2 6011 2 56 2 3682 2 12016 48 16 2 22 1554 25 2 26 2 19993 5989 101 23 2 139 2 13749 2 103 2 8118 16 40 2 19 2 2376 2 26 2 27894 3270 13125 18 2 30 2 69 2 39 2 2203 2 103 2 19 2 177 2 13749 2 139 2 15093 170 2 6305 2 70 2 27894 3270 13125 2 56 2 19 2 1974 2 26 2 19 2 67 937 2 1644 17 4 3 659 2 9170 5683 2 250 540 18 2 41 1223 98 2 332 131 18 2 21502 16 79 2 35 3346 2 30 2 4525 131 2917 2 1695 603 4700 2 26713 18 2 3117 7552 18 2 19 2 406 2 38 16 2 151 2 41 2 8506 18 2 9008 2 6067 2 5562 2 84 2 766 2 19519 2 70 2 84 2 560 2 35 2 28 2 2124 17 4 3 166 2 19 2 35388 2 11730 18 2 654 2 19 2 10683 8283 2 7684 2 30 2 19 2 101 3141 2 7684 2 139 2 26104 16 40 2 56 2 19 2 35388 2 636 2 48 2 582 2 19 2 22397 2 26 2 6653 25 3691 2 30 2 60 16 6238 16 40 2 35 2 19 2 312 2 359 2 26 2 371 7155 17 4 3 3039 2 3624 4 3 29805 2 24 2 67 2 2289 2 84 2 6591 2 66 2 28 2 636 2 631 2 22 35 2 10317 2 28 2 26110 81 4 3 67 2 41 2 19 2 356 2 351 2 26 2 19 2 5704 2 300 4827 18 2 30 2 84 2 1943 2 41 2 14806 391 2 151 2 41 2 28 2 1759 2 26 2 14806 4683 287 2 15552 1670 1106 17 4 3 67 2 41 2 6362 2 35 2 53 16 2 25 16508 2 22 732 100 23 2 27 2 1252 86 2 216 2 593 2 19 2 1273 2 277 2 66 2 582 2 17384 2 56 2 1256 16 3320 17 4 3 98 14806 2 131 2 13573 16862 16 2 131 2 10914 49 3714 16 2 41 2 143 2 3726 2 3491 17 4 3 19 2 19722 300 1079 2 7684 2 27 2 69 10852 18 2 101 7573 2 237 2 22 1400 2 941 28 14383 18 2 6936 28 3346 24 2139 18 2 48 4996 2 235 18 2 88 1578 300 2 7178 118 2 41 2 28 2 2964 2 312 2 26 2 19 2 19722 300 1079 2 7684 2 27 2 19 2 35 1578 6068 2 7684 2 30 2 41 2 28 2 29868 2 26 2 28 2 25 84 23363 2 312 2 48 2 418 2 48 2 19 2 3346 287 2 312 17 4 3 19 2 25 16 1869 16 2 26 2 19 2 5958 2 1733 2 27 2 19 2 1683 2 26 2 25 84 16 59 2 41 2 199 2 6074 18 2 216 2 19 2 763 2 26 2 19 2 3095 2 5958 2 592 2 7185 2 44 2092 101 2 12309 2 269 2 36316 17 44 4 3 72 7330 133 1324 2 22 28 2 1699 2 26 2 12765 25 2 19293 2 4904 2 27 2 19 2 1309 16 2 363 23 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 0 1 2 3 4 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 27631 58 25940 1350 6232 1058 596 2298 2038 64 4 3 19340 5893 369 20 357 716 947 31 2831 2583 2042 2000 1323 65 28948 12529 1769 4437 18255 31 34220 350 35443 11565 117 21 4 3 262 3723 186 19813 5733 1624 65 13954 4363 3190 46 30711 117 21 4 3 1468 2110 20042 20 23358 31 19615 32 34151 1468 31 32598 3749 4102 21 4 3 25755 184 2 22 23876 115 23 2 24 2 5062 23876 4237 21 4 3 1711 1905 1337 1811 31 5463 32 5183 1597 15590 46 3738 9312 6951 21 4 3 981 20 1017 4157 16347 355 65 940 4157 31 18417 2 22 382 11200 23 36 20 564 1857 355 31 7376 46 13596 10100 3165 452 20 9374 9631 186 564 1857 355 45 32454 4985 236 7409 21 4 3 9445 3506 109 26490 9985 892 20 7847 4620 5380 20 22658 2869 1016 1737 8612 35987 2229 20 7483 6937 14683 772 16464 36 20 39663 46 8001 6113 36719 616 29524 876 35648 242 21 4 3 24254 935 1226 1045 838 20 34877 838 7329 362 2742 45 781 3056 17998 119 4320 389 20 4431 838 45 7050 4527 99 21 4 3 13135 1036 4 3 21279 86 29 22 29805 29 23 2 24 2 13056 6569 22 28288 3091 46 11290 3875 23 46 262 1628 21 4 3 465 276 11562 2295 16930 20 10115 855 20315 475 4512 3882 2823 4512 188 21 4 3 37008 86 29 4283 2010 29 23 45 23068 17869 9415 20 20643 7316 45 37535 323 3385 21 4 3 27501 140 27800 14297 21 4 3 19659 220 6375 894 22 563 32 3257 1206 1624 115 6893 12383 475 430 23 31 27202 10837 21905 2047 27202 4223 27365 55 20 184 334 838 11164 1351 2094 31 13722 5383 34327 90 21 4 3 12453 1 238 13523 31 564 6400 1753 1109 36 24691 6668 42 20 19571 8341 564 9600 149 58 21454 454 809 86 7303 64 11800 21 4 3 785 2164 1183 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 0 1 2 3 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 0 1 2 3 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-15646', 'train-0-27451', 'train-0-19545', 'train-0-25661', 'train-0-17790', 'train-0-23669', 'train-0-26073', 'train-0-42671', 'train-0-36883', 'train-0-23432', 'train-0-23436', 'train-0-6537', 'train-0-5585', 'train-0-33430', 'train-0-24012', 'train-0-4034', 'train-0-33881']\n",
      "INFO:tensorflow:src_texts:[\"The expression 'Hongan-ji Temple power' is used here because 'Hongan-ji Temple school' would be confused with the current Jodo Shinshu Hongan-ji school (Nishi Hongan-ji Temple school).\", 'Kanji characters in gyosho (cursive style of writing kanji characters) or sosho (advanced cursive style of writing kanji characters, more abbreviated and flowing than gyosho), variant characters, hentaigana (anomalous Japanese cursive syllabary), auxiliary words of kanji writing in gyosho or sosho, hiragana (Japanese syllabary characters), katakana (fragmentary kana), combined characters, etc. were used.', 'This product was produced for the first time in July 2005 when the present Empress Michiko visited Yamaguchi Prefecture.', 'The kani soto (corresponding relationship between court ranks of government officials and government posts) changed from Shoshiinojo (Senior Fourth Rank, Upper Grade) to Jusanmi (Junior Third Rank).', 'There is a portrait (wooden statue) of Yoshizumi in Toji-in Temple of Kita-ku, Kyoto city.', 'A swallowtail butterfly was the representative Kamon (family crest) of the Taira clan.', 'There are 33 pairs mentioned below which are examples of the same town names that exist in different places within Kamigyo Ward.', 'Some people drink sobayu straight without mixing with soba sauce.', 'She got married to Emperor Daigo and became a nyogo (a consort of an emperor) in 901.', 'The third case; the hundred and nineteenth Emperor Kokaku.', 'Fire up the kiseru, moving the gankubi closer to charcoal fire on a tobacco tray.', 'At the ceremony held when Goshirakawa entered the priesthood, all eight monks followed by the priest who imparts the Buddhist commandments were from Onjo-ji Temple.', 'OTOMO no Tomokuni was a toneri (palace servant) serving Prince Oama when the Jinshin War started.', 'Many lines of Kyoto City Bus bring you to these two stops from other stops in Kyoto City, such as Kyoto Station, Kawaramachi Station (in Kyoto Prefecture), and Imadegawa Station.', 'At the end of the Edo period, the Choshu Domain and their followers, who resorted to drastic measures such as the rebellion at the Kinmon Gate, were first called a rebel army.', \"The family she stayed with was one of her mother Imperial Princess Kiko's acquaintances.\", 'According to historical materials such as \"Azuma Kagami\" and the \"Gyokuyo,\" a journal of Kanezane KUJO, armed priests of Enryaku-ji Temple of Mt. Hiei sheltered Yoshitsune and his retainers, who escaped from Kyoto and stayed hidden around Mt. Hiei; one of those priests named Shunsho took them to Oshu.']\n",
      "INFO:tensorflow:tar_texts:['本願寺勢力という言い方は、本願寺派とすると現在の浄土真宗本願寺派(西本願寺系）と混交するためである。', '使われる文字は、漢字の行草書・異体字・変体仮名・行草書の漢文の助辞・ひらがな・カタカナ・合字など。', 'これは、2005年7月現在皇后の皇后美智子が山口県を訪れた際に、初めて作られた。', '官位相当は正四位上から従三位に異動。', '肖像は京都市北区の等持院（木像）。', '家紋は揚羽蝶など。', '上京区では、同一の町名が区内の別の場所に複数存在する例が下記の33組ある。', '蕎麦つゆと割らず蕎麦湯のみを飲む人もいる。', '昌泰4年（901年）醍醐天皇に入内、女御となる。', '3例目の第119代光格天皇の場合。', '煙草盆の炭火に雁首を近づけて火を点ける。', '後白河が出家した際の儀式では、戒師以下8人の僧全員が園城寺の門徒だった。', '壬申の乱の勃発時、大伴友国は大海人皇子の舎人であった。', '京都市営バスは京都駅、河原町駅 (京都府)、今出川駅など京都市内各地から。', '幕末においては当初禁門の変などで強攻策を主張した長州藩及びその支持者が賊軍とされた。', 'ホームステイ先は母・紀子妃の知人宅であった。', '史料である『吾妻鏡』や『玉葉』によると、都落ちの後、周辺に潜伏する義経を比叡山の悪僧（僧兵）らが庇護しており、その中の俊章（しゅんしょう）という僧は義経を奥州まで案内したとされる。']\n",
      "INFO:tensorflow:Target:21271 7803 310 12905 20303 20 21271 1803 1315 65 862 37868 21271 1803 22 276 21271 999 23 65 10089 4618 5824 90 21 4 0 18179 3450 36 20 10514 31 569 1883 940 32 2894 971 1320 32 3949 971 17885 32 569 1883 940 31 3190 501 31 2827 12062 32 10394 42 228 32 11071 10236 32 1500 1320 247 21 4 0 2276 3712 29 85 11036 9513 31 9513 34134 42 5661 29447 9167 20 6388 7839 21 4 0 1132 358 15574 36 446 1351 358 262 102 24194 45 16480 21 4 0 38935 3151 36 11977 6212 31 718 3526 947 22 485 3151 414 4 0 339 10965 36 10809 1969 14946 247 21 4 0 14559 552 149 20 12382 10544 42 552 2693 8337 18863 10098 14389 2172 42 21256 889 1517 1552 21 4 0 39981 13067 588 4144 65 5861 7544 39981 13067 3009 1138 46 38053 172 19999 21 4 0 2225 2869 68 29 22 1252 43 29 23 30302 39997 3586 8360 430 20 1056 1350 344 21 4 0 54 2172 7040 107 8928 516 505 3166 3586 7951 21 4 0 12923 1883 22853 31 12803 1852 45 24214 3220 46 2583 16266 323 1852 46 1002 9151 21 4 0 465 17177 42 19775 17166 31 26431 149 20 14757 1577 5121 86 172 22311 27196 2346 435 12261 1036 10570 887 21 4 0 34498 9858 9275 31 19765 623 20 140 8184 2268 301 13102 621 172 16930 31 31734 482 21 4 0 1467 24885 36 1467 219 20 33866 219 2 22 4611 343 1780 954 18107 247 11977 430 13800 102 21 4 0 11078 805 26797 8656 1036 23433 3447 3310 12681 9424 30154 171 34360 30596 10738 6622 32085 876 9437 21 4 0 1955 27855 2081 36 2001 32 24246 7681 31 1070 172 8776 482 21 4 0 8767 90 63 17232 5056 74 109 63 1863 1627 74 4678 20 1662 9726 5383 20 3659 45 11385 10131 117 781 1857 46 2747 33001 8048 3538 7268 22 7268 1753 23 8612 38599 1967 20 307 3055 2239 1458 22 27622 2863 23 310 7268 36 781 1857 46 23190 616 5615 28136 21 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 19 2 11094 2 44 2732 72 24 1106 2 2559 2 1159 44 2 39 2 469 2 143 16 2 1663 2 44 2732 72 24 1106 2 2559 2 183 44 2 761 2 53 16 2 17708 2 70 2 19 2 1709 2 635 318 2 2917 5224 2 2732 72 24 1106 2 183 2 22 14602 2 2732 72 24 1106 2 2559 2 183 81 4 3 1670 1106 2 6185 2 27 2 92 1578 3682 2 22 2256 14357 16 2 742 2 26 2 3011 2 1670 1106 2 6185 23 2 100 2 320 3682 2 22 3024 2 2256 14357 16 2 742 2 26 2 3011 2 1670 1106 2 6185 18 2 368 2 25019 2 30 2 25969 2 579 2 92 1578 3682 118 2 16402 2 6185 18 2 4913 329 13189 28 2 22 3440 1117 2009 2 972 2 2256 14357 16 2 10489 4585 2034 118 2 22604 2 4694 2 26 2 1670 1106 2 3011 2 27 2 92 1578 3682 2 100 2 320 3682 18 2 13994 2133 28 2 22 972 2 10489 4585 2034 2 6185 118 2 11050 13283 2 22 17319 2034 2 13283 118 2 6913 2 6185 18 2 6644 17 2 139 2 469 17 4 3 135 2 4441 2 41 2 1362 2 52 2 19 2 121 2 246 2 27 2 211 2 401 2 303 2 19 2 1400 2 25028 2 22882 391 2 9438 2 35590 2 7178 17 4 3 19 2 1670 79 2 320 35 2 22 21275 2 7829 2 390 2 1101 2 14186 2 26 2 636 2 14391 2 30 2 636 2 631 25 23 2 3527 2 66 2 3682 1695 27 98 635 2 22 1832 2 2336 2 5170 18 2 3046 2 5357 23 2 35 2 1222 510 250 2 22 1963 2 923 2 5170 81 4 3 319 2 39 2 28 2 7657 2 22 10832 2 9588 23 2 26 2 6653 2778 250 2 27 2 35 1106 24 27 2 2559 2 26 2 10761 24 1079 18 2 18810 2 235 17 4 3 28 2 28281 5440 2 11708 2 41 2 19 2 4214 2 4763 38 2 22 312 2 16527 23 2 26 2 19 2 329 3124 2 7684 17 4 3 319 2 126 2 889 2 16487 2 7185 2 3178 2 124 2 126 2 11780 2 26 2 19 2 1273 2 370 2 737 2 103 2 11818 2 27 2 1818 2 1046 2 1300 2 11926 92 1578 2 2125 17 4 3 481 2 479 2 13792 2 320 1122 113 2 7491 2 2358 2 13680 2 70 2 320 617 2 25996 17 4 3 162 2 2679 2 1087 2 35 2 5704 2 5336 300 2 30 2 443 2 28 2 59 1578 300 2 22 28 2 26254 2 26 2 72 2 5704 23 2 27 2 87 4884 4 3 19 2 923 2 3155 93 2 19 2 7932 2 30 2 18673 2 5704 2 391 24662 17 4 3 1393 2 196 2 19 2 95 39 16 1026 18 2 5036 2 19 2 2133 1079 860 2 18452 2 35 2 3606 7253 2 1393 2 38 2 28 2 25520 2 80 1447 17 4 3 49 2 19 2 9733 2 685 2 303 2 300 28720 6547 2 4151 2 19 2 38660 18 2 163 2 2092 2 10675 25 2 3680 2 56 2 19 2 5067 2 151 2 1113 3422 2 19 2 16637 2 3582 9960 2 139 2 66 2 38 635 24 1106 2 2559 17 4 3 98 14806 2 131 2 14806 27720 2 41 2 28 2 615 16 630 2 22 5786 2 13288 23 2 2892 2 2418 2 98 6691 2 303 2 19 2 6368 2917 2 269 2 1409 17 4 3 624 2 3611 2 26 2 18810 2 235 2 1890 2 8547 2 549 2 35 2 1618 2 177 2 3559 25 2 66 2 283 2 3559 25 2 27 2 18810 2 235 18 2 644 2 48 2 18810 2 336 18 2 6547 6525 921 2 336 2 22 27 2 18810 2 7178 118 2 30 2 79 427 11549 2 336 17 4 3 49 2 19 2 914 2 26 2 19 2 16 318 2 1644 18 2 19 2 2139 5224 2 2839 2 30 2 223 2 32948 18 2 151 2 9847 16 40 2 35 2 3751 9807 2 15197 2 644 2 48 2 19 2 17656 2 49 2 19 2 2543 2054 2 3624 18 2 139 2 121 2 789 2 28 2 16232 2 1160 17 4 3 19 2 312 2 162 2 13159 2 70 2 41 2 38 16 2 26 2 143 2 1943 2 5975 2 6437 2 540 391 44 25 2 899 4587 27 2477 8704 17 4 3 1495 2 35 2 1413 2 8213 2 644 2 48 2 33 28 15499 28 2 332 24708 33 2 30 2 19 2 33 3270 11422 1578 18 33 2 28 2 678 2 26 2 1670 16 5545 16 2 1079 635 18 2 8506 2 5067 25 2 26 2 16 6146 19672 24 1106 2 2559 2 26 2 4917 17 2 1223 16 79 2 14365 16 40 2 6653 80 1287 16 2 30 2 84 2 14852 757 18 2 151 2 26713 2 66 2 18810 2 30 2 13159 2 14748 2 1080 2 4917 17 2 1223 16 79 93 2 38 16 2 26 2 1885 2 5067 25 2 640 2 24031 3682 2 1015 2 1075 2 35 2 98 5224 17 4 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 21271 7803 310 12905 20303 20 21271 1803 1315 65 862 37868 21271 1803 22 276 21271 999 23 65 10089 4618 5824 90 21 4 3 18179 3450 36 20 10514 31 569 1883 940 32 2894 971 1320 32 3949 971 17885 32 569 1883 940 31 3190 501 31 2827 12062 32 10394 42 228 32 11071 10236 32 1500 1320 247 21 4 3 2276 3712 29 85 11036 9513 31 9513 34134 42 5661 29447 9167 20 6388 7839 21 4 3 1132 358 15574 36 446 1351 358 262 102 24194 45 16480 21 4 3 38935 3151 36 11977 6212 31 718 3526 947 22 485 3151 414 4 3 339 10965 36 10809 1969 14946 247 21 4 3 14559 552 149 20 12382 10544 42 552 2693 8337 18863 10098 14389 2172 42 21256 889 1517 1552 21 4 3 39981 13067 588 4144 65 5861 7544 39981 13067 3009 1138 46 38053 172 19999 21 4 3 2225 2869 68 29 22 1252 43 29 23 30302 39997 3586 8360 430 20 1056 1350 344 21 4 3 54 2172 7040 107 8928 516 505 3166 3586 7951 21 4 3 12923 1883 22853 31 12803 1852 45 24214 3220 46 2583 16266 323 1852 46 1002 9151 21 4 3 465 17177 42 19775 17166 31 26431 149 20 14757 1577 5121 86 172 22311 27196 2346 435 12261 1036 10570 887 21 4 3 34498 9858 9275 31 19765 623 20 140 8184 2268 301 13102 621 172 16930 31 31734 482 21 4 3 1467 24885 36 1467 219 20 33866 219 2 22 4611 343 1780 954 18107 247 11977 430 13800 102 21 4 3 11078 805 26797 8656 1036 23433 3447 3310 12681 9424 30154 171 34360 30596 10738 6622 32085 876 9437 21 4 3 1955 27855 2081 36 2001 32 24246 7681 31 1070 172 8776 482 21 4 3 8767 90 63 17232 5056 74 109 63 1863 1627 74 4678 20 1662 9726 5383 20 3659 45 11385 10131 117 781 1857 46 2747 33001 8048 3538 7268 22 7268 1753 23 8612 38599 1967 20 307 3055 2239 1458 22 27622 2863 23 310 7268 36 781 1857 46 23190 616 5615 28136 21 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-16190', 'train-0-9688', 'train-0-29719', 'train-0-11475', 'train-0-23874', 'train-0-27742', 'train-0-11686', 'train-0-36295', 'train-0-32686', 'train-0-31395', 'train-0-35204', 'train-0-41033', 'train-0-4538', 'train-0-33182']\n",
      "INFO:tensorflow:src_texts:['A statue of a Buddhist monk, taken to be TAIRA no Kiyomori, holding scriptures.', \"However, it doesn't seem that it was operated as a complete system, given that the names of some people assigned were not described.\", \"A signature of 'Koji' and Kao (written seal mark) were engraved on the back side.\", 'During the same year, he became a priest at Daitoku-ji Temple and took the Buddhist name Sotan.', \"Beginning in Fiscal Year 2006, the following projects were carried out as part of the 'Randen Brush-up Project.'\", 'Yoritomo gave shoryo of Yoshihiro and samurai who followed Yoshihiro, to his own gokenin.', 'This color is also used for the special cars for the Imperial Family (with the exception of cars selected as ad-wrapped cars), and the interior is also finished in a uniform manner with panel boards in a woodtone finish and the seats covered with angora (goat) fabric dyed in colors listed in the Shikimei Ichiran (the standardized color list used in Japan) that begin with the Japanese letter \"こ\" (pronounced \"ko\").', 'In particular, in the Kanto region where fighting occurred frequently, local rich persons or powerful clans had come to bear public military burdens.', 'At this point, the territory of the Takeda family consisted of Shinano Province, Suruga Province, the western part of Kozuke Province, Totomi Province, Mikawa Province, Hida Province, and a part of Ecchu Province as well as Kai Province, and its (crop) yield reached 1,200,000 koku (0.3336 million cubic meters).', 'It is explained that because from 1989 JR Ashio Line no longer carried cargo and the imports of the raw material ore were reduced, the mining pollution was decreased.', 'The grave and the memorial tower of Madame Myoren are extant at Honno-ji Temple in Kyoto, Fukusho-ji Temple (Kagoshima City), and the remains of Kokubun Enju-ji Temple.', 'Komatsubara Honan is an incident that Nichiren was assaulted and injured in Komatsubara (present-day Kamogawa City, Chiba Prefecture).', 'Due to this, direct Imperial succession since Emperor Tenji and Emperor Tenmu, was not allowed, in fact Imperial succession between the eldest brothers was restored (even though it was only temporary).', 'The family crest of the Toki clan bears Mizuiro Kikyo-mon (a light blue-colored pattern of chinese bellflower), and is known for its colored pattern, not black and white.']\n",
      "INFO:tensorflow:tar_texts:['平清盛とされる経を持った僧形の像である。', 'ただし、任命されていた人物の名が記されていない場合もあり、完全なシステムとしてこのように運営されていたわけではないようである。', '裏面には「光次」の署名と花押が刻印されている。', '同年、大徳寺にて出家し、宗湛と号した。', '2006年度より「嵐電ブラッシュ・アップ プロジェクト」として以下のような事業を行っている。', '頼朝は義広とそれに与した武士の所領を自らの御家人に与える。', 'お召し列車でも用いられる色）が採用されている（ラッピング車両に抜擢された場合を除く）ほか、内装についても木目調の化粧板や色名一覧 (こ)色のアンゴラ (ヤギ)の毛のシートを採用するなど統一されている。', '特に争乱の多かった関東では、在地の富豪や豪族が公的な軍事力を担うようになっていた。', 'この時点で武田家の領土は、甲斐国一国のほか、信濃国、駿河国、上野国西部、遠江国・三河国・飛騨国・越中国の一部にまで及び、石高はおよそ120万石に達している。', '1989年にJR足尾線で貨物が廃止になると、原料鉱石の搬入量が減少し、鉱毒はさらに減少したとされる。', '京都の本能寺と福昌寺 (鹿児島市)、国分遠寿寺跡に、妙蓮夫人の墓と供養塔が現存。', '小松原法難（こまつばらほうなん）とは、小松原（現千葉県鴨川市）日蓮が襲撃され負傷した事件。', 'これにより、天智・天武以来の直系皇位継承は放棄され、大兄制が（一時的とは言え）事実上復活したと見ることも可能である。', '家紋は水色桔梗紋で、白黒紋でなく彩色紋として知られる。']\n",
      "INFO:tensorflow:Target:434 855 3809 2267 1857 15938 7268 11047 3151 90 21 4 0 2615 20 15108 2117 2398 31 6809 1311 5860 3543 6604 20 25729 1736 119 26185 3126 2117 27600 23785 21 4 0 35373 186 58 505 1174 64 31 21962 65 693 9072 42 8173 3798 511 21 4 0 905 20 140 26310 800 19775 97 20 1220 36885 38638 21 4 0 291 31574 58 8135 1998 2781 4541 32 4378 2 3755 64 119 28133 1092 5059 21 4 0 3040 1206 36 781 1129 65 16007 3706 99 11573 31 17548 46 15026 33706 45 3706 3939 21 4 0 439 13700 97 2971 837 13991 1439 23 42 29017 22 316 30037 3980 30938 171 3543 6334 23 1979 20 430 3970 11278 485 863 2210 31 33106 2809 109 1439 334 979 2 22 620 23 7177 33085 2 22 1000 1266 23 31 2498 31 14115 16035 6786 6088 511 21 4 0 2043 12829 4687 31 1384 4768 3010 149 20 2069 14149 1912 7136 109 29296 42 666 990 5653 1109 25738 2253 16829 21 4 0 258 6863 8245 2929 17069 36 20 12278 301 210 301 7159 20 34122 20 17372 301 20 5393 301 4165 20 33379 301 32 11141 301 32 16775 301 32 2074 727 2113 17015 886 20 573 357 36 10123 3161 17985 28609 417 21 4 0 1227 150 605 2182 1198 189 55 5509 42 2435 9034 20 17803 11312 573 31 38797 1295 2279 42 9028 97 20 11312 8832 36 1767 9028 28136 21 4 0 1467 11432 2960 475 65 1783 2225 475 2 22 20959 343 20772 3391 3254 475 3125 45 20 4830 5162 7751 15718 65 25063 4254 42 16494 21 4 0 7950 444 400 4864 22 620 7202 14024 4596 6101 23 521 20 7950 444 22 563 3258 30560 115 23 51 5162 42 19401 389 10823 99 1904 21 4 0 11014 20 782 2244 32 782 960 19817 967 999 6128 358 8409 36 31215 389 20 140 3825 1475 42 22 8195 702 521 3210 1037 23 18579 7447 99 65 11513 35286 90 21 4 0 339 10965 36 407 1439 39919 39862 10965 55 20 849 1491 10965 27783 4257 1439 10965 10617 21 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 28 2 9588 2 26 2 28 2 16637 2 10675 18 2 2901 2 35 2 53 16 2 329 3124 2 131 2 540 1578 6718 18 2 8371 2 5395 748 16 25 17 4 3 1039 18 2 69 2 19276 44 80 2 25 16 16 73 2 103 2 69 2 41 2 3377 2 48 2 28 2 2082 2 480 18 2 1721 2 103 2 19 2 737 2 26 2 481 2 479 2 6362 2 139 2 199 2 1581 17 4 3 28 2 19607 2 26 2 44 391 1106 44 2 30 2 332 98 2 22 1246 2 14370 2 1133 23 2 139 2 37895 2 38 2 19 2 560 2 592 17 4 3 279 2 19 2 1273 2 277 18 2 67 2 443 2 28 2 5067 2 49 2 5336 35 1079 24 1106 2 2559 2 30 2 1015 2 19 2 16637 2 359 2 320 2477 17 4 3 3189 2 27 2 23315 2 277 2 3804 2 19 2 598 2 5715 2 139 2 7300 2 296 2 48 2 285 2 26 2 19 2 44 1457 787 2 22506 24 196 2 998 17 44 4 3 101 4771 14806 2 3957 2 3682 17553 2 26 2 6653 5556 2 30 2 27027 2 151 2 3680 2 6653 5556 18 2 35 2 84 2 1279 2 300 1585 27 17 4 3 135 2 3535 2 39 2 123 2 469 2 52 2 19 2 1178 2 5037 2 52 2 19 2 5975 2 312 2 22 70 2 19 2 17042 2 26 2 5037 2 2944 2 48 2 895 24 39399 2 5037 118 2 30 2 19 2 5136 2 39 2 123 2 1988 2 27 2 28 2 12652 2 14246 2 70 2 9608 2 18431 2 27 2 28 2 900 615 16 2 5080 2 30 2 19 2 5799 2 4336 2 70 2 72 2571 28 2 22 300 49 23 2 16002 2 1761 16 40 2 27 2 12913 2 1547 2 27 2 19 2 1695 2868 16 79 2 4640 827 2 22 19 2 2450 2666 2 3535 2 225 2 469 2 27 2 778 23 2 103 2 8627 2 70 2 19 2 972 2 4974 2 33 620 33 2 22 15643 2 33 391 33 81 4 3 27 2 6544 18 2 27 2 19 2 1670 35 2 917 2 317 2 5253 2 11308 2 9919 18 2 735 2 2130 2 11367 2 100 2 12718 2 7684 25 2 176 2 96 16 2 35 2 5735 2 556 2 1558 2 3030 7596 17 4 3 49 2 135 2 1304 18 2 19 2 4799 2 26 2 19 2 1427 352 2 312 2 9004 2 26 2 2917 3440 2 865 18 2 1485 12541 2 865 18 2 19 2 867 2 285 2 26 2 391 142 387 16 2 865 18 2 35 35 250 2 865 18 2 250 6547 2 865 18 2 26003 2 865 18 2 30 2 28 2 285 2 26 2 16 78 3487 2 865 2 48 2 418 2 48 2 4197 2 865 18 2 30 2 154 2 22 19099 23 2 22765 2 3489 2 750 33822 2 27586 2 22 8073 20509 2 1878 2 31669 2 7475 81 4 3 69 2 39 2 25095 2 103 2 1663 2 66 2 1227 2 605 2 2599 1853 2 513 2 131 2 6398 2 7300 2 12947 2 30 2 19 2 14935 25 2 26 2 19 2 7804 2 3750 2 100 16 2 139 2 11355 18 2 19 2 7899 2 32867 2 41 2 26330 40 17 4 3 19 2 4064 2 30 2 19 2 3317 2 3039 2 26 2 73 3854 16 2 27894 1681 2 126 2 28653 2 49 2 4623 131 24 1106 2 2559 2 27 2 18810 18 2 22597 3682 24 1106 2 2559 2 22 332 300 10673 2 235 118 2 30 2 19 2 4939 2 26 2 27586 5560 2 16 59 1222 24 1106 2 2559 17 4 3 391 8283 11246 2 4623 72 2 39 2 72 2 10063 2 103 2 59 6667 1681 2 41 2 16511 16 40 2 30 2 12320 2 27 2 391 8283 11246 2 22 1400 24 504 2 332 603 11549 2 235 18 2 32389 2 7178 81 4 3 273 16 2 35 2 135 18 2 4425 2 5975 2 19794 2 550 2 5704 2 743 1106 2 30 2 5704 2 743 1232 18 2 41 2 199 2 6349 18 2 27 2 4664 2 5975 2 19794 2 390 2 19 2 14351 2 3814 2 41 2 12253 2 22 4428 2 3113 2 69 2 41 2 406 2 15023 81 4 3 19 2 312 2 16527 2 26 2 19 2 35 540 2 7684 2 10430 2 28893 5118 2 540 19722 24 2054 2 22 28 2 1256 2 1342 24 21346 2 13477 2 26 2 1234 2 1598 6205 118 2 30 2 39 2 305 2 52 2 154 2 21346 2 13477 18 2 199 2 753 2 30 2 839 17 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 434 855 3809 2267 1857 15938 7268 11047 3151 90 21 4 3 2615 20 15108 2117 2398 31 6809 1311 5860 3543 6604 20 25729 1736 119 26185 3126 2117 27600 23785 21 4 3 35373 186 58 505 1174 64 31 21962 65 693 9072 42 8173 3798 511 21 4 3 905 20 140 26310 800 19775 97 20 1220 36885 38638 21 4 3 291 31574 58 8135 1998 2781 4541 32 4378 2 3755 64 119 28133 1092 5059 21 4 3 3040 1206 36 781 1129 65 16007 3706 99 11573 31 17548 46 15026 33706 45 3706 3939 21 4 3 439 13700 97 2971 837 13991 1439 23 42 29017 22 316 30037 3980 30938 171 3543 6334 23 1979 20 430 3970 11278 485 863 2210 31 33106 2809 109 1439 334 979 2 22 620 23 7177 33085 2 22 1000 1266 23 31 2498 31 14115 16035 6786 6088 511 21 4 3 2043 12829 4687 31 1384 4768 3010 149 20 2069 14149 1912 7136 109 29296 42 666 990 5653 1109 25738 2253 16829 21 4 3 258 6863 8245 2929 17069 36 20 12278 301 210 301 7159 20 34122 20 17372 301 20 5393 301 4165 20 33379 301 32 11141 301 32 16775 301 32 2074 727 2113 17015 886 20 573 357 36 10123 3161 17985 28609 417 21 4 3 1227 150 605 2182 1198 189 55 5509 42 2435 9034 20 17803 11312 573 31 38797 1295 2279 42 9028 97 20 11312 8832 36 1767 9028 28136 21 4 3 1467 11432 2960 475 65 1783 2225 475 2 22 20959 343 20772 3391 3254 475 3125 45 20 4830 5162 7751 15718 65 25063 4254 42 16494 21 4 3 7950 444 400 4864 22 620 7202 14024 4596 6101 23 521 20 7950 444 22 563 3258 30560 115 23 51 5162 42 19401 389 10823 99 1904 21 4 3 11014 20 782 2244 32 782 960 19817 967 999 6128 358 8409 36 31215 389 20 140 3825 1475 42 22 8195 702 521 3210 1037 23 18579 7447 99 65 11513 35286 90 21 4 3 339 10965 36 407 1439 39919 39862 10965 55 20 849 1491 10965 27783 4257 1439 10965 10617 21 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1 2 3 4 5 6 7 8 9 10 11 12 13 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Making training data...\n",
      "INFO:tensorflow:Loading examples\n",
      "INFO:tensorflow:***** FitGenerator Summary *****\n",
      "INFO:tensorflow:Num_all_examples=399239\n",
      "INFO:tensorflow:sum_src_tokens=22643532\n",
      "INFO:tensorflow:sum_tar_tokens=9989804\n",
      "INFO:tensorflow:Batch_size=8\n",
      "INFO:tensorflow:encoder_input_len=1024\n",
      "INFO:tensorflow:decoder_input_len=1024\n",
      "INFO:tensorflow:packing_factor=0.950\n",
      "INFO:tensorflow:approximate_steps_per_epoch=2909\n",
      "INFO:tensorflow:num_epoch=5\n",
      "INFO:tensorflow:total_step=14545\n",
      "INFO:tensorflow:Elapsed_sec_before_fit_generator=119.165\n",
      "INFO:tensorflow:Preparing new records\n",
      "INFO:tensorflow:New file created model/translator_en_ja/train.tfrecord.0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-362188', 'train-0-173615', 'train-0-345282', 'train-0-385980', 'train-0-272740', 'train-0-58903', 'train-0-27848', 'train-0-154454', 'train-0-210113', 'train-0-216952', 'train-0-23679', 'train-0-124314', 'train-0-390738', 'train-0-339637', 'train-0-228412', 'train-0-325432', 'train-0-301367', 'train-0-247327', 'train-0-166115', 'train-0-156265']\n",
      "INFO:tensorflow:src_texts:['This is when the movement to reevaluate Moshi occurred.', 'The song is based on the legendary duel between MINAMOTO no Yoshitsune (Ushiwakamaru) and Musashibo Benkei on Gojo-ohashi Bridge in Kyoto.', 'The Shohei Itto was established and when rumors arose that Emperor Gomurakami was to return to Kyoto, Southern Court supporters in various regions grew active and transferred the main headquarters from Ano to Tojo (Kanancho) Kawachi Province to Sumiyoshi Settsu Province (Sumiyoshi Ward, Osaka City).', 'His first wife was Shimo and his second was Saki.', \"I will open a hole in the his storehouse, and drop in this sword, when you wake in the morning, then give this sword to the child of the heavenly gods.'\", \"Kyoto Koka Women's University\", 'He is considered to have inherited from his father, Shigenao Shokan shiki (officer entrusted with local management by the lord of the private estate [Honjo]) of Asuke-no-sho (manor), Kamo district, Mikawa Province, and constructed there Kibyu-jo Castle, where he lived in.', 'During the Onin War, members of the clan had served Kanrei (Shogunal deputy) Katsumoto HOSOKAWA and fought battles as was the case for other governors.', 'Meanwhile, kouchigi (literally \"small uchigi\") were created for occasions when juni-hitoe were too formal, but everyday clothes might be impolite.', 'In 1104, Jusanmi (Junior Third Rank), Shuri no daibu', '962', 'But Saneyori became ill and died in the following year, 970.', 'Also, there are many towns named after warlords who served under Hideyoshi, such as Nyosui-cho, Kodera-cho, Ukita-cho, Hidadono-cho, Tamura-Bizen-cho, Fukushima-cho, Chusho-cho, and Naoie-cho.', 'While hoshi-imo is produced nationwide in Japan, more than 80 percent of hoshi-imo is industrially produced in Ibaraki Prefecture.', 'In 1437, he was appointed to Ukone no daisho (the major captain of the right division of inner palace guards).', 'The government did not respect this decision at all.', 'The sect began in Kamakura in 1282 when Sogen MUGAKU was invited from China.', 'However, jokotoba is different from makura word in that the number of syllabic sounds is not fixed and there are longer jokotoba, and that the modified word is not fixed and created.', \"In the Chinese (Tang) ritsuryo that shaped the Japanese counterpart, however, the Soniryo belonged to the 'Dosokyaku' (code for priests) that covered Taoists in Taoism.\", 'Short sword, owned by Yomei Bunko, Kyoto']\n",
      "INFO:tensorflow:tar_texts:['ここに孟子の再評価の動きが起こった。', '源義経（牛若丸）が武蔵坊弁慶と京都の五条大橋で争ったと伝えられる伝説に基づいたもの。', '正平一統が成立し、南朝の後村上天皇が帰京する噂が立つと、各地で南朝方の活動が活発化し、本拠を賀名生から河内国東条（河南町）、摂津国住吉（大阪市住吉区）まで移転する。', '妻はしも後にさき。', '「この剣を高倉下の倉に落とし入れることにしよう。お前は朝目覚めたら、天つ神の御子に献上しろ」', '京都光華女子大学', '父重直より三河国加茂郡 (三河国)足助荘の荘官職を継承し、同地に黍生城を築き居住したとされる。', '先の応仁の乱では、幕府の管領を務めた細川勝元に従って、他の国人衆とともに合戦に参加した。', '一方、十二単を着るほどでもなく、平服でも失礼な場合の時に着用する着物として小袿なる物が発明される。', '康和6年（1104年）従三位、修理大夫', '- 962年', 'だが、翌天禄元年（970年）に病に倒れ薨去。', 'また「如水町」「小寺町」「浮田町」「飛弾殿町」「田村備前町」「福島町」「中書町」「直家町」など秀吉騎下の武将の名を冠した地名も多く見られる。', '日本においては全国各地で作られているが、産業としては8割以上が茨城県で生産されている。', '永享9年（1437年）右近衛大将に任じられる。', 'それを留守政府が大きく反故にしてしまっていた。', '1282年 中国から招かれた無学祖元により鎌倉で始まる。', 'ただし枕詞とは、音数が自由で長いものが見られる点と、受ける語が固定されず自由であり創作性に富んでいる点で異なる。', 'ただし、日本律令法の母法である中国（唐）律令法では、道教の道士を含めた格式である「道僧格」に属していた。', '短刀（京都・陽明文庫蔵）']\n",
      "INFO:tensorflow:Target:19340 23696 188 15433 3948 29363 42 17400 21 4 0 33207 1857 22 3593 3069 1341 23 42 10142 5836 4529 2799 65 1467 31 1205 1482 5098 55 12829 711 26678 5280 35035 1375 21 4 0 446 434 210 9278 11565 97 20 20379 5383 6738 3586 42 4895 2102 117 23662 42 20506 65 20 23896 20379 1060 12154 42 25717 16924 20 30495 46 3313 334 412 102 6464 301 249 1482 22 32274 138 343 21273 301 12353 22 6035 12353 552 23 616 5789 117 21 4 0 19933 13659 935 6909 21 4 0 58 258 5007 46 27209 8839 2294 45 19451 16120 11585 23712 21 439 453 36 1206 36202 12704 20 782 588 596 31 1350 15494 10589 262 12420 64 4 0 1467 505 2080 14278 4 0 1808 852 967 342 11141 301 10204 220 2 22 11141 301 23 2182 2827 4511 31 4511 28509 20691 97 20 23685 45 1 412 435 37659 12824 28136 21 4 0 15826 4437 1757 9275 149 20 8787 31 3357 1718 2308 12688 618 328 17620 20 2426 301 172 7102 1490 13597 10525 21 4 0 5349 20 8383 3359 46 1204 194 2828 55 23557 20 434 4613 837 6293 4515 228 3543 21052 17221 117 1204 877 119 335 1 3416 877 42 14270 404 21 4 0 2021 528 83 29 3704 1661 29 23 24194 20 14820 17781 4 0 24 2 2338 50 29 4 0 1894 20 2387 782 14936 2108 22 26690 29 23 45 2739 45 22144 31675 21 4 0 254 58 5733 407 138 1386 335 21424 1386 6763 7334 1386 5331 2544 4456 138 1386 3953 23247 138 1386 4609 138 1386 206 940 138 1386 967 339 138 64 247 26993 11661 377 12317 31 5471 4228 99 4485 14438 12594 21 4 0 168 4095 32523 55 31553 42 20 2116 1870 86 5861 3208 42 3827 55 2527 511 21 4 0 1492 17937 87 29 3826 1050 29 23 2393 14014 12417 17869 194 21 4 0 8106 28836 2742 18249 2593 7454 6113 5750 3405 21 4 0 89 2482 29 2 727 102 12427 15531 1175 572 3745 328 325 7410 55 5867 4118 21 4 0 2615 20707 7653 521 20 1017 13972 3853 55 6816 1375 14729 1002 65 20 6775 194 680 42 10451 19023 3853 452 14159 612 45 1912 10369 20234 5524 21 4 0 2615 20 168 7088 3474 400 8318 400 90 727 22 4137 23 7088 3474 400 149 20 355 1712 13030 1364 23608 3166 903 90 58 355 7268 3166 64 29947 21 4 0 5237 5488 22 1467 32 1448 564 2046 2000 23 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 135 2 39 2 303 2 19 2 3315 2 35 2 60 16 31995 16 2 603 1695 2 11308 17 4 3 19 2 437 2 39 2 638 2 38 2 19 2 18928 2 273 16 76 2 390 2 8384 6728 2 131 2 6653 80 1287 16 2 22 23832 21909 15082 23 2 30 2 1817 28 1695 770 2 1216 9605 2 38 2 300 635 24 98 26580 2 1310 2 27 2 18810 17 4 3 19 2 3682 67 79 2 69 35 2 41 2 1333 2 30 2 303 2 3553 100 25 2 28 4142 2 103 2 5704 2 300 6784 11926 2 41 2 35 2 2974 2 35 2 18810 18 2 1218 2 1101 2 21056 2 27 2 1667 2 7568 2 5731 2 2438 2 30 2 5726 2 19 2 691 2 6322 2 66 2 3440 2 35 2 35 635 2 22 1670 72 2139 23 2 6547 921 2 865 2 35 2 27081 6653 2 878 4683 2 865 2 22 27081 6653 2 2125 18 2 11348 2 235 81 4 3 84 2 121 2 1669 2 41 2 1695 603 2 30 2 84 2 356 2 41 2 14783 17 4 3 79 2 613 2 995 2 28 2 2940 16 2 27 2 19 2 84 2 3456 311 18 2 30 2 6856 2 27 2 135 2 14417 18 2 303 2 549 2 10240 2 27 2 19 2 3547 18 2 517 2 4788 2 135 2 14417 2 35 2 19 2 2483 2 26 2 19 2 8229 170 2 20551 17 44 4 3 18810 2 17679 28 2 558 44 25 2 160 4 3 67 2 39 2 2203 2 35 2 289 2 19447 2 66 2 84 2 1166 18 2 29865 16632 2 3682 1670 2 1695 540 2 22 2365 2 16 59 2949 16 40 2 70 2 735 2 2036 2 56 2 19 2 2348 2 26 2 19 2 2296 2 16 205 2 200 4623 635 11259 2 26 2 48 387 16 24 131 24 3682 2 22 10262 118 2 332 603 2 255 18 2 250 6547 2 865 18 2 30 2 4536 2 319 2 540 56 113 24 635 2 2197 18 2 317 2 67 2 3217 2 27 17 4 3 279 2 19 2 38 27 2 269 18 2 1076 2 26 2 19 2 7684 2 176 2 599 2 1670 6409 2 22 3682 2107 134 2 4442 23 2 19922 6728 2 840 320 6547 2 30 2 9008 2 1683 25 2 48 2 41 2 19 2 3155 2 52 2 283 2 2175 25 17 4 3 21311 18 2 391 14383 902 2 22 17073 2 33 868 2 14383 902 33 23 2 139 2 1700 2 52 2 17070 2 303 2 2609 79 24 1223 35 16 2 139 2 4114 2 10821 18 2 216 2 26641 2 28555 2 9304 2 53 16 2 1113 18308 16 17 4 3 27 2 4343 1441 2 1222 510 250 2 22 1963 2 923 2 5170 118 2 609 3847 2 131 2 5336 1675 4 3 2338 50 4 3 216 2 510 16 101 4771 2 443 2 2948 2 30 2 593 2 27 2 19 2 598 2 277 18 2 26690 17 4 3 123 18 2 319 2 126 2 624 2 4776 2 640 2 166 2 269 17168 2 151 2 599 2 293 2 10873 6653 18 2 644 2 48 2 59 1578 18659 24 2139 18 2 391 472 28 24 2139 18 2 113 10761 24 2139 18 2 26003 318 131 24 2139 18 2 329 6784 24 10397 16 59 24 2139 18 2 22597 10673 24 2139 18 2 3487 3682 24 2139 18 2 30 2 16632 79 16 24 2139 17 4 3 659 2 840 1695 24 17066 2 39 2 1362 2 22815 2 27 2 778 18 2 368 2 579 2 1317 2 12146 2 26 2 840 1695 24 17066 2 39 2 4847 170 2 1362 2 27 2 79 32858 79 2 7178 17 4 3 27 2 145 1050 18 2 67 2 41 2 1539 2 35 2 387 38 16 2 131 2 5336 3682 2 22 19 2 958 2 2644 2 26 2 19 2 1379 2 670 2 26 2 6995 2 5786 2 19096 81 4 3 19 2 636 2 1250 2 199 2 9509 2 135 2 5033 2 49 2 163 17 4 3 19 2 24893 2 1085 2 27 2 4763 28 19093 2 27 2 89 2482 2 303 2 320 831 2 1232 19130 2 41 2 10805 2 66 2 1168 17 4 3 1039 18 2 635 391 35 617 2 39 2 1818 2 66 2 267 19093 2 2986 2 27 2 103 2 19 2 595 2 26 2 10489 4585 252 2 13105 2 39 2 199 2 14997 2 30 2 319 2 126 2 6398 2 635 391 35 617 18 2 30 2 103 2 19 2 15078 2 2986 2 39 2 199 2 14997 2 30 2 1700 17 4 3 27 2 19 2 1234 2 22 5675 23 2 630 4683 17553 2 103 2 8056 2 19 2 972 2 31640 18 2 1039 18 2 19 2 351 79 17553 2 17204 2 35 2 19 2 44 4052 2402 19672 44 2 22 2206 2 52 2 5067 25 23 2 103 2 4336 2 18582 6907 2 27 2 18582 1631 17 4 3 1072 2 14417 18 2 2297 2 56 2 1578 9214 2 5560 391 18 2 18810 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 0 1 2 3 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 19340 23696 188 15433 3948 29363 42 17400 21 4 3 33207 1857 22 3593 3069 1341 23 42 10142 5836 4529 2799 65 1467 31 1205 1482 5098 55 12829 711 26678 5280 35035 1375 21 4 3 446 434 210 9278 11565 97 20 20379 5383 6738 3586 42 4895 2102 117 23662 42 20506 65 20 23896 20379 1060 12154 42 25717 16924 20 30495 46 3313 334 412 102 6464 301 249 1482 22 32274 138 343 21273 301 12353 22 6035 12353 552 23 616 5789 117 21 4 3 19933 13659 935 6909 21 4 3 58 258 5007 46 27209 8839 2294 45 19451 16120 11585 23712 21 439 453 36 1206 36202 12704 20 782 588 596 31 1350 15494 10589 262 12420 64 4 3 1467 505 2080 14278 4 3 1808 852 967 342 11141 301 10204 220 2 22 11141 301 23 2182 2827 4511 31 4511 28509 20691 97 20 23685 45 1 412 435 37659 12824 28136 21 4 3 15826 4437 1757 9275 149 20 8787 31 3357 1718 2308 12688 618 328 17620 20 2426 301 172 7102 1490 13597 10525 21 4 3 5349 20 8383 3359 46 1204 194 2828 55 23557 20 434 4613 837 6293 4515 228 3543 21052 17221 117 1204 877 119 335 1 3416 877 42 14270 404 21 4 3 2021 528 83 29 3704 1661 29 23 24194 20 14820 17781 4 3 24 2 2338 50 29 4 3 1894 20 2387 782 14936 2108 22 26690 29 23 45 2739 45 22144 31675 21 4 3 254 58 5733 407 138 1386 335 21424 1386 6763 7334 1386 5331 2544 4456 138 1386 3953 23247 138 1386 4609 138 1386 206 940 138 1386 967 339 138 64 247 26993 11661 377 12317 31 5471 4228 99 4485 14438 12594 21 4 3 168 4095 32523 55 31553 42 20 2116 1870 86 5861 3208 42 3827 55 2527 511 21 4 3 1492 17937 87 29 3826 1050 29 23 2393 14014 12417 17869 194 21 4 3 8106 28836 2742 18249 2593 7454 6113 5750 3405 21 4 3 89 2482 29 2 727 102 12427 15531 1175 572 3745 328 325 7410 55 5867 4118 21 4 3 2615 20707 7653 521 20 1017 13972 3853 55 6816 1375 14729 1002 65 20 6775 194 680 42 10451 19023 3853 452 14159 612 45 1912 10369 20234 5524 21 4 3 2615 20 168 7088 3474 400 8318 400 90 727 22 4137 23 7088 3474 400 149 20 355 1712 13030 1364 23608 3166 903 90 58 355 7268 3166 64 29947 21 4 3 5237 5488 22 1467 32 1448 564 2046 2000 23 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 0 1 2 3 4 5 6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 1 2 3 4 5 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 0 1 2 3 4 5 6 7 8 9 10 11 12 13 0 1 2 3 4 5 6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 0 1 2 3 4 5 6 7 8 9 10 11 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-41269', 'train-0-172452', 'train-0-47678', 'train-0-34794', 'train-0-282962', 'train-0-232860', 'train-0-174958', 'train-0-143886', 'train-0-323820', 'train-0-265040', 'train-0-25727', 'train-0-142189', 'train-0-161952', 'train-0-131682', 'train-0-79298', 'train-0-125153', 'train-0-62343', 'train-0-127802']\n",
      "INFO:tensorflow:src_texts:['The origin of firecrackers', 'He was actually more adept at doing cultural activities than business, so he entrusted a job to a chief clerk in spite of taking over the family business, and was busy doing lessons in various personal accomplishments.', 'Donryu solidified the foundation of this venue which became established among the danrin temples as a seminary for Jodo sect trainee priests.', 'Otagi Nenbutsu-ji Temple - a temple famous for its 1200 Rakan (arhat, Lohan, achiever of Nirvana)', 'Geothermal Research Laboratory (Beppu City, Oita Prefecture)', 'The Samurai soldiers were assigned to such posts as the \"Hokumen no bushi\" which was newly established to protect the retired Emperor.', 'Corey NAKATANI', 'Converting the Edo-jo Castle to the Imperial Palace', 'The section from this station to Kizu Station came into operation.', 'Actually, there were a number of Korean people who crossed the border, then negotiations between Korea and the Qing dynasty were held regarding protection of the Koreans even after Korea became the Korean empire, and the borders of the Tumen river and the Yalu river gradually became an accomplished fact.', \"In the Imperial House of Japan, the Imperial family's Shini includes the Empress, the Grand Empress Dowager, the Empress Dowager, crown prince, crown princess, the son of crown prince, the daughter of crown prince, Imperial Prince, Imperial Princess (wife of Imperial Prince), Imperial Princess (daughter of the Emperor), King (of the Imperial family), Queen (wife of King), and Queen (sister of the King born into the Imperial family).\", 'The Ocho period (Dynastic period) is a Japanese historical period.', 'Chikei (landscape)', 'Private First ABE said they remembered starting on the third day and that they just realized they were going into the shack, not knowing what they had done until then.', 'During the Heian period, establishing a soja near the kokufu (provincial office) and worshiping at it became wide spread to save the tour of every shrine.', 'It disappeared as a sect and was incorporated into the Rinzai sect (in addition, the Ichigetsu-dera Temple belongs to the present Nichiren Sho Sect).', 'Dagashi was named to mark the contrast with \"jogashi\", which were snacks of a higher quality, and in the Kansai area dagashi are also called \"zatsugashi\" (miscellaneous confectionery).', 'While Fuki used entertainers belonging to Shinsei Production (one of origins of current Shochiku Geino Co., Ltd), all entertainers belonging to Sentochi Kogyo, many of them were quite popular at the time, performed at Kyoraku Theater.']\n",
      "INFO:tensorflow:tar_texts:['由来と爆竹', '元来商売より文化活動に向いていた人物で、後を嗣いでも商売は番頭に任せ、諸芸の稽古に精を出していたという。', '浄土宗檀林（浄土宗僧侶の養成所）の基礎固めを行った。', '愛宕念仏寺 - 千二百羅漢の寺', '地球熱学研究施設（大分県別府市）', '武士は、院の警護役として創設した北面の武士になどにあてた。', 'コーリー・ナカタニ', '江戸城から皇居へ', '当駅～木津間の新線が開通。', '実際にはこの「国境」を越えた清朝領域に越境した朝鮮人が多数に上ったため、彼らをどう保護するかという問題とも絡んで、この後大韓帝国となっても清朝との国境線画定の話し合いは断続的に行われたが、豆満江・鴨緑江を国境線とすることが次第に既成事実化していった。', '日本の皇室において、皇族の身位とは、皇后、太皇太后、皇太后、皇太子、皇太子妃、皇太孫、皇太孫妃、親王、親王妃、内親王、王 (皇族)、王妃 (皇族)、女王 (皇族)をいう。', '王朝時代（おうちょうじだい）は日本史上における時代区分の一つ。', '地景（ちけい）', '3日目に出発したところまでは覚えているが、それ以降は分からず、気づいたら小屋に飛び込んでいたという内容の証言をしている。', '平安時代になって国府の近くに総社を設け、そこを詣でることで巡回を省くことが広まった。', '宗派としては失われ、臨済宗に編入された（ちなみに一月寺は現在日蓮正宗に属する）。', '駄菓子という名称は、当時の高級菓子の名称である上菓子の対照としてつけられたもので、関西地方では雑菓子（ざつがし）とも称されている。', '富貴は新生プロダクション（現在の松竹芸能の母体の一つ）などから芸人を調達していたが、当時売れっ子が多かった千土地興行所属の芸人はすべて京洛劇場に出演した。']\n",
      "INFO:tensorflow:Target:6328 65 10083 2404 4 0 328 1624 37226 342 963 1221 45 2758 13576 2398 55 20 465 46 8422 315 837 37226 36 776 1042 45 2783 1942 20 3081 5502 31 31990 45 3789 19110 772 310 21 4 0 32240 25515 1009 22 32240 23789 31 27638 23 14373 22120 3479 21 4 0 25755 38182 475 2 24 2 1369 530 2513 4363 3190 31 475 4 0 3851 2455 572 1034 1354 22 5967 15608 115 23 4 0 11573 36 20 947 31 38856 584 119 6840 99 337 16711 11573 45 4957 30086 171 21 4 0 2459 679 32 24116 22458 4 0 3062 435 102 6128 3012 381 4 0 6431 397 485 1188 5590 245 189 19206 21 4 0 16800 258 58 11772 64 46 27072 171 32364 7633 45 2074 4058 99 28083 20425 45 262 711 797 20 16048 46 2818 4249 24012 310 2007 1191 18808 5186 20 258 465 140 6541 3910 6876 129 32364 35903 189 2017 1316 18792 97 8973 36 5112 5397 1833 6518 42 20 9054 2525 765 32 12487 4432 765 46 11772 15751 13808 15251 25388 920 17008 581 22332 21 4 0 383 32633 805 20 31233 31 2176 358 521 20 9513 20 1182 35881 20 35881 20 21527 20 21527 7681 20 6128 1182 3643 20 6128 1182 3643 7681 20 11388 20 1915 16142 20 430 11388 20 580 2 22 31233 343 16142 2 22 31233 343 9851 2 22 31233 23 22099 21 4 0 12068 2452 22 7385 3621 1165 2961 23 15215 10622 874 2452 13641 2537 21 4 0 546 2704 22 1235 4843 23 4 0 54 51 12474 15658 26210 6116 25654 17172 20 26163 36 22207 1888 20 1595 7360 1249 642 16528 45 10020 15876 1249 310 4730 31 25322 7191 21 4 0 9374 7522 18517 31 17557 25733 14238 20 14841 46 33600 55 3875 55 27456 46 2187 487 3747 1129 11433 21 4 0 1220 1803 1870 33595 20 27801 20685 22 12453 210 37 475 20815 38483 5084 414 4 0 20635 9784 18412 36 20 2473 12451 9784 29999 262 9784 31 26891 119 30289 8529 20 3218 1355 149 6515 9784 22 4041 588 42 97 23 1191 5060 511 21 4 0 1912 2488 36 23137 6449 22 862 11639 8749 31 19968 2537 23 15618 13751 46 25518 4448 20 1619 30005 22513 21608 1369 5201 12687 9496 13751 19983 2102 22060 2803 20867 21 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 19 2 4837 2 26 2 1393 14618 757 4 3 67 2 41 2 9668 2 368 2 28 23574 2 49 2 12263 2 2891 2 4920 2 579 2 918 18 2 320 2 67 2 16 59 2949 16 40 2 28 2 5549 2 35 2 28 2 1503 2 13101 2 27 2 15440 16 2 26 2 4134 2 253 2 19 2 312 2 918 18 2 30 2 41 2 26459 2 12263 2 18240 2 27 2 1667 2 3546 2 37881 25 17 4 3 646 23610 2 8966 9052 2 19 2 1790 2 26 2 135 2 11320 2 124 2 443 2 1333 2 1625 2 19 2 1751 60 27 2 2559 25 2 48 2 28 2 15071 2 52 2 635 318 2 24893 2 2698 16 16 2 5067 25 17 4 3 9571 902 2 7093 216 690 24 1106 2 2559 2 24 2 28 2 2559 2 2910 2 52 2 154 2 15677 2 7330 72 2 22 261 3117 18 2 20782 72 18 2 18453 60 2 26 2 17695 657 28 23 4 3 4079 20925 2 825 2 8784 2 22 53 16 361 113 2 235 18 2 98 69 28 2 7178 23 4 3 19 2 27027 2 8215 2 139 2 6362 2 35 2 644 2 631 25 2 48 2 19 2 33 23363 326 2 131 2 5605 79 33 2 124 2 41 2 7894 2 1333 2 35 2 8252 2 19 2 2191 2 5704 17 4 3 1296 16 101 2 9636 12701 4 3 16750 112 2 19 2 16 318 24 635 2 2197 2 35 2 19 2 5975 2 5786 4 3 19 2 2156 2 66 2 135 2 336 2 35 2 540 2778 2 336 2 2020 2 403 2 3877 17 4 3 9668 18 2 319 2 139 2 28 2 595 2 26 2 3154 2 479 2 151 2 21491 2 19 2 3601 18 2 517 2 26394 25 2 390 2 3390 2 30 2 19 2 16724 2 7383 2 139 2 685 2 14483 2 6782 2 26 2 19 2 3154 25 2 4428 2 166 2 3390 2 443 2 19 2 3154 2 3347 18 2 30 2 19 2 10918 2 26 2 19 2 1170 326 2 447 2 30 2 19 2 913 1301 2 447 2 22157 2 443 2 72 2 30018 2 4664 17 4 3 27 2 19 2 5975 2 311 2 26 2 778 18 2 19 2 5975 2 312 44 25 2 2917 79 2 2002 2 19 2 25028 18 2 19 2 1025 2 25028 2 9717 28 1130 18 2 19 2 25028 2 9717 28 1130 18 2 5863 2 2418 18 2 5863 2 6437 18 2 19 2 351 2 26 2 5863 2 2418 18 2 19 2 1759 2 26 2 5863 2 2418 18 2 5975 2 2418 18 2 5975 2 6437 2 22 1669 2 26 2 5975 2 2418 118 2 5975 2 6437 2 22 1759 2 26 2 19 2 5704 118 2 676 2 22 26 2 19 2 5975 2 312 118 2 2451 2 22 1669 2 26 2 676 118 2 30 2 2451 2 22 3491 2 26 2 19 2 676 2 144 2 403 2 19 2 5975 2 312 81 4 3 19 2 98 2139 2 1644 2 22 21218 48 2165 2 1644 23 2 39 2 28 2 972 2 1413 2 1644 17 4 3 25502 16 79 2 22 7321 23 4 3 2296 2 121 2 1640 16 2 2369 2 270 2 19875 2 4393 2 38 2 19 2 923 2 504 2 30 2 103 2 270 2 1210 2 19456 40 2 270 2 139 2 4159 2 403 2 19 2 25 9152 18 2 199 2 3711 112 2 1365 2 270 2 176 2 646 16 2 498 2 517 17 4 3 279 2 19 2 67 937 2 1644 18 2 20518 2 28 2 320 561 2 1031 2 19 2 27586 2309 2 22 4679 2 647 23 2 30 2 14590 112 2 49 2 69 2 443 2 2968 2 6637 2 35 2 9797 2 19 2 1048 2 26 2 16 684 2 14702 17 4 3 69 2 28503 2 48 2 28 2 24893 2 30 2 41 2 8164 2 403 2 19 2 60 27 19611 2 24893 2 22 27 2 2759 18 2 19 2 6667 6666 113 24 472 28 2 2559 2 11888 2 35 2 19 2 1400 2 59 6667 1681 2 3682 2 24893 81 4 3 10109 28 1695 2 41 2 640 2 35 2 1133 2 19 2 15582 2 70 2 33 635 806 1695 650 2 124 2 139 2 25 19080 25 2 26 2 28 2 3812 2 5290 18 2 30 2 27 2 19 2 1670 4827 2 440 2 10109 28 1695 2 126 2 123 2 789 2 33 803 4683 806 1695 33 2 22 21022 2 11099 16 8447 16 713 81 4 3 659 2 2309 540 2 469 2 34390 25 2 12924 2 35 2 2917 15552 2 1529 2 22 38 16 2 26 2 12375 2 26 2 1709 2 3682 921 1079 2 92 16 27 98 2 155 17 18 2 2343 118 2 163 2 34390 25 2 12924 2 35 2 1169 35 921 2 391 92 1578 18 2 624 2 26 2 1075 2 139 2 5347 16 2 1881 2 49 2 19 2 246 18 2 2600 2 49 2 19722 365 1079 2 4111 17 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 0 1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 6328 65 10083 2404 4 3 328 1624 37226 342 963 1221 45 2758 13576 2398 55 20 465 46 8422 315 837 37226 36 776 1042 45 2783 1942 20 3081 5502 31 31990 45 3789 19110 772 310 21 4 3 32240 25515 1009 22 32240 23789 31 27638 23 14373 22120 3479 21 4 3 25755 38182 475 2 24 2 1369 530 2513 4363 3190 31 475 4 3 3851 2455 572 1034 1354 22 5967 15608 115 23 4 3 11573 36 20 947 31 38856 584 119 6840 99 337 16711 11573 45 4957 30086 171 21 4 3 2459 679 32 24116 22458 4 3 3062 435 102 6128 3012 381 4 3 6431 397 485 1188 5590 245 189 19206 21 4 3 16800 258 58 11772 64 46 27072 171 32364 7633 45 2074 4058 99 28083 20425 45 262 711 797 20 16048 46 2818 4249 24012 310 2007 1191 18808 5186 20 258 465 140 6541 3910 6876 129 32364 35903 189 2017 1316 18792 97 8973 36 5112 5397 1833 6518 42 20 9054 2525 765 32 12487 4432 765 46 11772 15751 13808 15251 25388 920 17008 581 22332 21 4 3 383 32633 805 20 31233 31 2176 358 521 20 9513 20 1182 35881 20 35881 20 21527 20 21527 7681 20 6128 1182 3643 20 6128 1182 3643 7681 20 11388 20 1915 16142 20 430 11388 20 580 2 22 31233 343 16142 2 22 31233 343 9851 2 22 31233 23 22099 21 4 3 12068 2452 22 7385 3621 1165 2961 23 15215 10622 874 2452 13641 2537 21 4 3 546 2704 22 1235 4843 23 4 3 54 51 12474 15658 26210 6116 25654 17172 20 26163 36 22207 1888 20 1595 7360 1249 642 16528 45 10020 15876 1249 310 4730 31 25322 7191 21 4 3 9374 7522 18517 31 17557 25733 14238 20 14841 46 33600 55 3875 55 27456 46 2187 487 3747 1129 11433 21 4 3 1220 1803 1870 33595 20 27801 20685 22 12453 210 37 475 20815 38483 5084 414 4 3 20635 9784 18412 36 20 2473 12451 9784 29999 262 9784 31 26891 119 30289 8529 20 3218 1355 149 6515 9784 22 4041 588 42 97 23 1191 5060 511 21 4 3 1912 2488 36 23137 6449 22 862 11639 8749 31 19968 2537 23 15618 13751 46 25518 4448 20 1619 30005 22513 21608 1369 5201 12687 9496 13751 19983 2102 22060 2803 20867 21 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0 1 2 3 4 5 6 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guids:['train-0-60698', 'train-0-136623', 'train-0-2003', 'train-0-242675', 'train-0-336910', 'train-0-52373', 'train-0-347368', 'train-0-111380', 'train-0-18419', 'train-0-321820', 'train-0-308458', 'train-0-34385', 'train-0-14106', 'train-0-282889', 'train-0-302585', 'train-0-369486', 'train-0-303310', 'train-0-261399', 'train-0-327680', 'train-0-36968', 'train-0-268474', 'train-0-242680', 'train-0-185886', 'train-0-254607', 'train-0-297899']\n",
      "INFO:tensorflow:src_texts:['Kuminohama Hot Spring', 'Hatenashi Village', 'Kingo NAKAMURA: Left the group by June 1867', \"Oni-oi-shiki' (a ceremony to exorcise evil) held on the night of April 5, the final day, puts an end to the Buddhist memorial service.\", 'Ouchi-juku on the old Aizunishi-kaido Road (Shimogo-machi, Minami Aizu-gun, Fukushima Prefecture)', 'Seishi Bosatsu zo with color painting on silk', 'Because it was a main current to be cut square around the collar until the mid Showa period, even now some people prefer that old-fashioned image.', \"In August, Terutora led his forces to Kawanakajima to prevent Shingen's forces from invading Hida Province.\", \"March 28: Shosanmi (Senior Third Rank) (as a prize of Kotaigo (queen dowager), TAIRA no Shigeko's formally entering Dairi Castle)\", 'Coagulation', \"People eat dango sweets called 'Mayudama' (cocoon-shaped) made of rice powders to pray for good health.\", 'Byodo-in Temple Hoodo (Phoenix Hall), Chuson-ji Temple Konjikido (Golden Hall), Shiramizu Amidado Hall, Fuki-ji Temple Odo Hall', 'On April 10, 1961, three pieces of earthenware had their designations as important cultural properties canceled.', 'One tang', 'That was Mount Kurama.', '(July 6, 1945-)', \"Under the auspices of Arinori MORI, Japan's first ambassador to the United States, Joe--who had first entered the U.S. as an illegal immigrant--was officially recognized as a legal foreign exchange student.\", 'In addition, during World War II, the US military forces regarded the castles as military facilities and attacked them from the air, and so many more were lost.', 'Fragrant olive (natural monument) in Sakuramoto-bo Temple', 'His two daughters respectively got married to Shunichi NAGAOKA (Ambassador of France, Ambassador of Germany) and Tsunejiro HONDO (Army Surgeon of Japanese Army).', 'About the document', 'He was the seventh family head of the CHIBA clan.', \"- Road sign with the engraving saying 'Nakasen-do and Minoji to the right and Kinshoku-ji Temple 45 cho (about 5 km) and Konohama Port to the left.'\", \"Then, as soldiers led by Yasushige MAKINO (the lord of the Ogo domain) were provoked by Masayuki's dare and triggered the battle, Masayuki agitated and threw out Tokugawa's army with an army of only 3500 strong.\", 'On May 18, also assumed the position of Togu no fu (an official in charge of education of the Crown Prince, Imperial Prince Morihira, later Emperor Juntoku).']\n",
      "INFO:tensorflow:tar_texts:['久美の浜温泉郷', '果無集落', '中村金吾……1867年6月迄に離隊。', '最終日の4月5日の夜には「鬼追式」が法会を締めくくる。', '旧会津西街道 大内宿 （福島県南会津郡下郷町）', '絹本著色勢至菩薩像', '昭和中期までは襟周りが角ばっているものが主流であったため、現在でもその古めかしいイメージを好む者もいる。', '8月、輝虎は信玄の飛騨国侵入を防ぐため、川中島に出陣した。', '3月28日正三位（皇太后・平滋子入内の賞）', '凝固', '「繭玉」と呼ばれる米の粉で作った団子を柳の枝に刺して焼いたものを食べ、無病息災の祈願をする。', '- 平等院鳳凰堂、中尊寺金色堂、白水阿弥陀堂、富貴寺大堂', '1961年（昭和36年）4月10日付けで陶器3件が重要文化財の指定を解除された。', '1 担', 'その山が鞍馬山であった。', '（1945年7月6日 -）', '当初密入国者として渡米した襄であったが、初代の駐米公使となった森有礼によって正式な留学生として認可された。', 'さらに、第二次世界大戦時にはアメリカ合衆国軍はこれを軍事施設とみなしたので、空襲を受けて更に多くが失われた。', '桜本坊のギンモクセイ（天然記念物）', '2人の娘はそれぞれ長岡春一（駐フランス大使・駐ドイツ大使）、本堂恒次郎（陸軍軍医）に嫁ぐ。', '書誌', '千葉氏第7代当主。', '- 「右 中山道 并 美濃路\\u3000左 錦織寺 四十五丁 こ乃者満ミち」とある道標。', 'そして牧野康成 (大胡藩主)率いる手勢が昌幸の挑発に乗ったのをきっかけに戦端が開かれると、昌幸はわずか3500の兵力で徳川軍をかき回して混乱に陥れた。', '4月15日、東宮（のちの順徳天皇こと守成親王）傅を兼任。']\n",
      "INFO:tensorflow:Target:31471 31 2068 1796 1094 4 0 8087 1175 8200 4 0 2281 457 5107 14710 6589 29 83 37 39728 45 4564 1469 21 4 0 4755 2099 68 37 77 51 14849 186 58 4138 4796 903 64 42 400 445 46 26764 487 9339 21 4 0 664 9284 276 2518 2 15109 3070 2 22 4384 288 9284 220 377 1094 138 23 4 0 21053 268 1902 1439 3926 5893 17787 3151 4 0 167 9631 6116 37903 20010 42 2333 1615 1773 10582 1323 957 14390 20 15999 307 1058 1049 396 4248 7068 36807 454 19999 21 4 0 86 37 20 3988 5737 36 814 5181 31 16775 301 22474 36524 20 238 6001 45 30135 99 21 4 0 54 37 192 51 36232 22 35881 32 434 21393 188 1295 2693 656 23 4 0 22983 8239 4 0 58 39735 1863 64 2325 1606 31 10611 55 18554 2070 188 46 2813 31 3622 45 8481 260 5379 1249 1375 31377 20 1175 2739 9073 25116 31 27728 6275 21 4 0 24 2 434 718 947 37979 1193 20 206 5469 475 457 1439 1193 20 849 407 35964 1193 20 1912 2488 475 140 1193 4 0 1748 29 22 167 885 29 983 37 82 31137 33007 54 7216 42 22479 31 2787 46 16555 236 21 4 0 43 2 11529 4 0 307 184 42 13983 873 184 482 21 4 0 22 1956 29 85 37 83 51 2 24 23 4 0 9237 3976 1295 301 15447 30827 99 21299 3334 20 2486 31 7259 1606 26152 376 1294 1217 4515 495 22620 27483 119 11548 236 21 4 0 1767 20 9584 6519 1949 13254 5001 5653 1354 19630 99 3940 20 19104 5857 8682 8259 42 26479 21 4 0 2433 268 5836 31 14261 844 292 5619 22 22337 23 4 0 50 172 2823 24328 9826 1187 210 22 7259 1155 5313 32 7259 1422 5313 343 14717 6934 3600 22 3360 876 3560 23 45 13300 3079 21 4 0 940 1811 4 0 3596 838 107 85 13606 21 4 0 24 2 58 2393 2 4720 355 2 1 2 10933 1474 2 2235 2 6722 7551 475 2 1351 16784 6558 2 620 5234 454 2525 585 1235 64 11800 355 13854 21 4 0 2411 15272 2021 920 2 22 140 10637 5718 23 10075 665 3926 42 2225 1453 31 23650 1497 45 3831 711 31 19106 567 3864 37889 3797 20 2225 1453 36 8611 54 1321 31 1753 1109 55 10587 17917 26368 244 260 19651 45 16679 6674 21 4 0 68 37 127 51 20 249 824 22 17674 2822 33092 1086 1666 920 11388 23 31672 27449 21 4 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Token-Ids:3 1079 23202 14595 2 1696 2 2900 4 3 3117 16 287 1695 2 364 4 3 676 98 2 32784 34 2 1035 2 19 2 399 2 56 2 224 2 6589 4 3 8125 24 10852 24 1695 540 44 2 22 28 2 9733 2 35 2 16 141 100 12399 16 2 16 4241 23 2 685 2 38 2 19 2 1406 2 26 2 213 2 1649 2 19 2 632 2 504 18 2 2140 25 2 72 2 914 2 35 2 19 2 16637 2 3317 2 459 17 4 3 98 14383 24 1222 1079 2 38 2 19 2 705 2 3438 2778 14602 24 4197 318 2 633 2 22 1695 603 300 24 21615 18 2 35034 2 3438 2778 24 2107 18 2 22597 10673 2 7178 23 4 3 25 16 13312 2 6366 49 690 2 2169 2 70 2 3535 2 5142 2 38 2 14678 4 3 1663 2 69 2 41 2 28 2 691 2 1709 2 35 2 53 16 2 2408 2 1502 2 1080 2 19 2 27135 2 498 2 19 2 1416 2 696 28 2 1644 18 2 4428 2 541 2 481 2 479 2 71 687 2 103 2 705 24 5287 16 40 2 4482 17 4 3 27 2 202 18 2 941 113 35 365 2 1019 2 84 2 3145 2 35 2 6547 9636 19379 2 35 2 9090 2 12262 16 59 44 25 2 3145 2 66 2 27 11260 112 2 26003 2 865 17 4 3 180 2 192 34 2 3682 510 250 2 22 1832 2 923 2 5170 23 2 22 48 2 28 2 2101 2 26 2 22858 79 300 2 22 2451 2 9717 28 1130 118 2 329 3124 2 131 2 29865 391 44 25 2 13282 2 4930 2 352 6621 2 2197 23 4 3 155 1599 19395 4 3 479 2 16 49 2 1751 300 2 4188 25 2 789 2 44 125 9548 267 44 2 22 17028 38 24 8056 23 2 427 2 26 2 1999 16 2 20061 25 2 35 2 20075 2 52 2 1420 2 1962 17 4 3 56 13125 24 27 2 2559 2 7838 98 2 22 9730 2 764 118 2 3487 351 24 1106 2 2559 2 3688 1106 540 318 2 22 3160 2 764 118 2 28720 28893 2 18099 5673 2 764 18 2 2309 540 24 1106 2 2559 2 13125 2 764 4 3 38 2 213 2 2577 2 1748 18 2 349 2 8858 2 26 2 2843 16 59 269 16 2 176 2 223 2 14063 25 2 48 2 2762 2 2891 2 5690 2 302 78 16 1019 17 4 3 38 16 2 5675 4 3 103 2 41 2 2713 2 19093 267 17 4 3 22 211 2 1781 2 1956 24 23 4 3 293 2 19 2 816 19147 25 2 26 2 2340 21767 2 6718 18 2 778 44 25 2 121 2 7392 2 35 2 19 2 207 2 264 18 2 635 16 24 24 151 2 176 2 121 2 4151 2 19 2 113 17 25 17 2 48 2 72 2 19119 2 29934 24 24 41 2 6064 2 7299 2 48 2 28 2 4196 2 2761 2 5147 2 3464 17 4 3 27 2 2759 18 2 279 2 156 2 269 2 380 18 2 19 2 133 2 1558 2 3145 2 14108 2 19 2 2197 25 2 48 2 1558 2 6198 2 30 2 17147 2 1075 2 66 2 19 2 554 18 2 30 2 320 2 624 2 368 2 139 2 1533 17 4 3 4544 4033 2 14715 2 22 1329 2 6655 23 2 27 2 24179 6728 24 770 2 2559 4 3 84 2 177 2 9212 2 8579 2 2679 2 1087 2 35 2 24031 6667 2 8898 6068 2 22 7392 2 26 2 1013 18 2 7392 2 26 2 1397 23 2 30 2 80 1287 16 104 5118 2 4623 318 2 22 1160 2 13638 2 26 2 972 2 1160 81 4 3 338 2 19 2 6729 4 3 67 2 41 2 19 2 7143 2 312 2 597 2 26 2 19 2 32389 2 7684 17 4 3 24 2 633 2 2551 2 70 2 19 2 35540 2 11568 2 44 9636 1169 24 318 2 30 2 23202 1106 2 35 2 19 2 1379 2 30 2 8723 23363 24 1106 2 2559 2 725 2 2139 2 22 338 2 77 2 241 23 2 30 2 391 131 14595 2 1161 2 35 2 19 2 1035 17 44 4 3 517 18 2 48 2 8215 2 1019 2 56 2 16281 29865 2 23729 131 2 22 19 2 2348 2 26 2 19 2 98 300 2 2839 23 2 139 2 31353 95 16 40 2 56 2 8821 9297 44 25 2 1676 16 2 30 2 23085 16 40 2 19 2 1683 18 2 8821 9297 2 1599 69 49 16 40 2 30 2 27658 2 296 2 38666 44 25 2 1160 2 70 2 72 2 1160 2 26 2 406 2 54 1321 2 3603 17 4 3 38 2 125 2 2185 2 123 2 15778 2 19 2 1717 2 26 2 35 1097 2 131 2 2309 2 22 72 2 309 2 27 2 5739 2 26 2 1145 2 26 2 19 2 5863 2 2418 18 2 5975 2 2418 2 6718 13994 18 2 408 2 5704 2 2609 35 1079 81 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Pos-Ids:0 1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 0 1 2 3 4 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 0 1 2 3 4 5 0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 0 1 2 3 4 5 6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Encoder-Group-Ids:0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Token-Ids:3 31471 31 2068 1796 1094 4 3 8087 1175 8200 4 3 2281 457 5107 14710 6589 29 83 37 39728 45 4564 1469 21 4 3 4755 2099 68 37 77 51 14849 186 58 4138 4796 903 64 42 400 445 46 26764 487 9339 21 4 3 664 9284 276 2518 2 15109 3070 2 22 4384 288 9284 220 377 1094 138 23 4 3 21053 268 1902 1439 3926 5893 17787 3151 4 3 167 9631 6116 37903 20010 42 2333 1615 1773 10582 1323 957 14390 20 15999 307 1058 1049 396 4248 7068 36807 454 19999 21 4 3 86 37 20 3988 5737 36 814 5181 31 16775 301 22474 36524 20 238 6001 45 30135 99 21 4 3 54 37 192 51 36232 22 35881 32 434 21393 188 1295 2693 656 23 4 3 22983 8239 4 3 58 39735 1863 64 2325 1606 31 10611 55 18554 2070 188 46 2813 31 3622 45 8481 260 5379 1249 1375 31377 20 1175 2739 9073 25116 31 27728 6275 21 4 3 24 2 434 718 947 37979 1193 20 206 5469 475 457 1439 1193 20 849 407 35964 1193 20 1912 2488 475 140 1193 4 3 1748 29 22 167 885 29 983 37 82 31137 33007 54 7216 42 22479 31 2787 46 16555 236 21 4 3 43 2 11529 4 3 307 184 42 13983 873 184 482 21 4 3 22 1956 29 85 37 83 51 2 24 23 4 3 9237 3976 1295 301 15447 30827 99 21299 3334 20 2486 31 7259 1606 26152 376 1294 1217 4515 495 22620 27483 119 11548 236 21 4 3 1767 20 9584 6519 1949 13254 5001 5653 1354 19630 99 3940 20 19104 5857 8682 8259 42 26479 21 4 3 2433 268 5836 31 14261 844 292 5619 22 22337 23 4 3 50 172 2823 24328 9826 1187 210 22 7259 1155 5313 32 7259 1422 5313 343 14717 6934 3600 22 3360 876 3560 23 45 13300 3079 21 4 3 940 1811 4 3 3596 838 107 85 13606 21 4 3 24 2 58 2393 2 4720 355 2 1 2 10933 1474 2 2235 2 6722 7551 475 2 1351 16784 6558 2 620 5234 454 2525 585 1235 64 11800 355 13854 21 4 3 2411 15272 2021 920 2 22 140 10637 5718 23 10075 665 3926 42 2225 1453 31 23650 1497 45 3831 711 31 19106 567 3864 37889 3797 20 2225 1453 36 8611 54 1321 31 1753 1109 55 10587 17917 26368 244 260 19651 45 16679 6674 21 4 3 68 37 127 51 20 249 824 22 17674 2822 33092 1086 1666 920 11388 23 31672 27449 21 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Pos-Ids:0 1 2 3 4 5 6 0 1 2 3 4 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 0 1 2 3 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0 1 2 3 4 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 4 5 6 7 8 9 10 11 12 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 0 1 2 3 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:Decoder-Group-Ids:0 0 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 20 20 20 20 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "INFO:tensorflow:New file created model/translator_en_ja/train.tfrecord.1\n",
      "INFO:tensorflow:New file created model/translator_en_ja/train.tfrecord.2\n",
      "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(1,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Token-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Pos-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Group-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Token-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Pos-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Group-Ids_10'), TensorSpec(shape=(1, 1024, 1), dtype=tf.float32, name='Output_target_10')]\n",
      "INFO:tensorflow:Overriding default placeholder.\n",
      "INFO:tensorflow:Cloning Adam {'lr': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9800000190734863, 'decay': 0.0, 'epsilon': 1e-08, 'amsgrad': False}\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Token-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Pos-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Group-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Token-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Pos-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Group-Ids\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f337f0e2a20> []\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Started compiling\n",
      "INFO:tensorflow:Finished compiling. Time elapsed: 151.101322889328 secs\n",
      "INFO:tensorflow:Setting weights on TPU model.\n",
      "INFO:tensorflow:CPU -> TPU lr: 0.0 {0.0}\n",
      "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
      "INFO:tensorflow:CPU -> TPU beta_2: 0.9800000190734863 {0.98}\n",
      "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
      "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
      "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
      "WARNING:tensorflow:Method (on_train_batch_begin) is slow compared to the batch update (0.988424). Check your callbacks.\n",
      "step_run=100 step_total=100 step_per_epoch=2909 loss=9.4850 masked_sparse_categorical_accuracy=0.0247 lr=7.0605e-06\n",
      "step_run=200 step_total=200 step_per_epoch=2909 loss=7.9419 masked_sparse_categorical_accuracy=0.0880 lr=2.1324e-05\n",
      "step_run=300 step_total=300 step_per_epoch=2909 loss=7.0836 masked_sparse_categorical_accuracy=0.1150 lr=3.5588e-05\n",
      "step_run=400 step_total=400 step_per_epoch=2909 loss=6.6925 masked_sparse_categorical_accuracy=0.1323 lr=4.9851e-05\n",
      "step_run=500 step_total=500 step_per_epoch=2909 loss=6.4778 masked_sparse_categorical_accuracy=0.1460 lr=6.4115e-05\n",
      "step_run=600 step_total=600 step_per_epoch=2909 loss=6.2601 masked_sparse_categorical_accuracy=0.1570 lr=7.8379e-05\n",
      "step_run=700 step_total=700 step_per_epoch=2909 loss=6.0509 masked_sparse_categorical_accuracy=0.1664 lr=9.2642e-05\n",
      "step_run=800 step_total=800 step_per_epoch=2909 loss=5.8428 masked_sparse_categorical_accuracy=0.1747 lr=1.0691e-04\n",
      "step_run=900 step_total=900 step_per_epoch=2909 loss=5.6704 masked_sparse_categorical_accuracy=0.1822 lr=1.2117e-04\n",
      "step_run=1000 step_total=1000 step_per_epoch=2909 loss=5.4782 masked_sparse_categorical_accuracy=0.1893 lr=1.3543e-04\n",
      "step_run=1100 step_total=1100 step_per_epoch=2909 loss=5.3226 masked_sparse_categorical_accuracy=0.1959 lr=1.4970e-04\n",
      "step_run=1200 step_total=1200 step_per_epoch=2909 loss=5.1945 masked_sparse_categorical_accuracy=0.2021 lr=1.6396e-04\n",
      "step_run=1300 step_total=1300 step_per_epoch=2909 loss=5.0609 masked_sparse_categorical_accuracy=0.2079 lr=1.7822e-04\n",
      "step_run=1400 step_total=1400 step_per_epoch=2909 loss=4.9368 masked_sparse_categorical_accuracy=0.2136 lr=1.9249e-04\n",
      "step_run=1500 step_total=1500 step_per_epoch=2909 loss=4.8364 masked_sparse_categorical_accuracy=0.2189 lr=2.0675e-04\n",
      "step_run=1600 step_total=1600 step_per_epoch=2909 loss=4.7440 masked_sparse_categorical_accuracy=0.2240 lr=2.2101e-04\n",
      "step_run=1700 step_total=1700 step_per_epoch=2909 loss=4.6301 masked_sparse_categorical_accuracy=0.2289 lr=2.3528e-04\n",
      "step_run=1800 step_total=1800 step_per_epoch=2909 loss=4.5514 masked_sparse_categorical_accuracy=0.2337 lr=2.4954e-04\n",
      "step_run=1900 step_total=1900 step_per_epoch=2909 loss=4.4756 masked_sparse_categorical_accuracy=0.2383 lr=2.6381e-04\n",
      "step_run=2000 step_total=2000 step_per_epoch=2909 loss=4.3939 masked_sparse_categorical_accuracy=0.2426 lr=2.7807e-04\n",
      "step_run=2100 step_total=2100 step_per_epoch=2909 loss=4.3145 masked_sparse_categorical_accuracy=0.2469 lr=2.9233e-04\n",
      "step_run=2200 step_total=2200 step_per_epoch=2909 loss=4.2594 masked_sparse_categorical_accuracy=0.2509 lr=3.0660e-04\n",
      "step_run=2300 step_total=2300 step_per_epoch=2909 loss=4.2120 masked_sparse_categorical_accuracy=0.2548 lr=3.2086e-04\n",
      "step_run=2400 step_total=2400 step_per_epoch=2909 loss=4.1300 masked_sparse_categorical_accuracy=0.2586 lr=3.3512e-04\n",
      "step_run=2500 step_total=2500 step_per_epoch=2909 loss=4.0998 masked_sparse_categorical_accuracy=0.2622 lr=3.4939e-04\n",
      "step_run=2600 step_total=2600 step_per_epoch=2909 loss=4.0385 masked_sparse_categorical_accuracy=0.2657 lr=3.6365e-04\n",
      "INFO:tensorflow:Preparing new records\n",
      "step_run=2700 step_total=2700 step_per_epoch=2909 loss=3.9237 masked_sparse_categorical_accuracy=0.2692 lr=3.7791e-04\n",
      "step_run=2800 step_total=2800 step_per_epoch=2909 loss=3.8537 masked_sparse_categorical_accuracy=0.2728 lr=3.9218e-04\n",
      "step_run=2900 step_total=2900 step_per_epoch=2909 loss=3.8236 masked_sparse_categorical_accuracy=0.2762 lr=4.0644e-04\n",
      "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(1,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Token-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Pos-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Encoder-Group-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Token-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Pos-Ids_10'), TensorSpec(shape=(1, 1024), dtype=tf.int32, name='Decoder-Group-Ids_10'), TensorSpec(shape=(1, 1024, 1), dtype=tf.float32, name='Output_target_10')]\n",
      "INFO:tensorflow:Overriding default placeholder.\n",
      "INFO:tensorflow:Cloning Adam {'lr': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9800000190734863, 'decay': 0.0, 'epsilon': 1e-08, 'amsgrad': False}\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Token-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Pos-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Encoder-Group-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Token-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Pos-Ids\n",
      "INFO:tensorflow:Remapping placeholder for Decoder-Group-Ids\n",
      "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f334eb84cc0> []\n",
      "INFO:tensorflow:Started compiling\n",
      "INFO:tensorflow:Finished compiling. Time elapsed: 67.5693416595459 secs\n",
      "296/296 [==============================] - 147s 498ms/step - loss: 3.8432 - masked_sparse_categorical_accuracy: 0.3716\n",
      "step_run=3000 step_total=3000 step_per_epoch=2909 loss=3.7968 masked_sparse_categorical_accuracy=0.3626 lr=4.2071e-04\n",
      "step_run=3100 step_total=3100 step_per_epoch=2909 loss=3.7822 masked_sparse_categorical_accuracy=0.3728 lr=4.3497e-04\n",
      "step_run=3200 step_total=3200 step_per_epoch=2909 loss=3.7428 masked_sparse_categorical_accuracy=0.3739 lr=4.4923e-04\n",
      "step_run=3300 step_total=3300 step_per_epoch=2909 loss=3.7120 masked_sparse_categorical_accuracy=0.3755 lr=4.6350e-04\n",
      "step_run=3400 step_total=3400 step_per_epoch=2909 loss=3.7058 masked_sparse_categorical_accuracy=0.3768 lr=4.7776e-04\n",
      "step_run=3500 step_total=3500 step_per_epoch=2909 loss=3.6901 masked_sparse_categorical_accuracy=0.3778 lr=4.9202e-04\n",
      "step_run=3600 step_total=3600 step_per_epoch=2909 loss=3.6483 masked_sparse_categorical_accuracy=0.3790 lr=5.0629e-04\n",
      "step_run=3700 step_total=3700 step_per_epoch=2909 loss=3.6308 masked_sparse_categorical_accuracy=0.3801 lr=5.2055e-04\n",
      "step_run=3800 step_total=3800 step_per_epoch=2909 loss=3.6277 masked_sparse_categorical_accuracy=0.3810 lr=5.3481e-04\n",
      "step_run=3900 step_total=3900 step_per_epoch=2909 loss=3.6016 masked_sparse_categorical_accuracy=0.3817 lr=5.4908e-04\n",
      "step_run=4000 step_total=4000 step_per_epoch=2909 loss=3.5861 masked_sparse_categorical_accuracy=0.3828 lr=5.6334e-04\n",
      "step_run=4100 step_total=4100 step_per_epoch=2909 loss=3.5768 masked_sparse_categorical_accuracy=0.3837 lr=5.6706e-04\n",
      "step_run=4200 step_total=4200 step_per_epoch=2909 loss=3.5264 masked_sparse_categorical_accuracy=0.3847 lr=5.6018e-04\n",
      "step_run=4300 step_total=4300 step_per_epoch=2909 loss=3.5022 masked_sparse_categorical_accuracy=0.3858 lr=5.5355e-04\n",
      "step_run=4400 step_total=4400 step_per_epoch=2909 loss=3.4764 masked_sparse_categorical_accuracy=0.3869 lr=5.4715e-04\n",
      "step_run=4500 step_total=4500 step_per_epoch=2909 loss=3.4356 masked_sparse_categorical_accuracy=0.3882 lr=5.4097e-04\n",
      "step_run=4600 step_total=4600 step_per_epoch=2909 loss=3.4216 masked_sparse_categorical_accuracy=0.3895 lr=5.3499e-04\n",
      "step_run=4700 step_total=4700 step_per_epoch=2909 loss=3.3866 masked_sparse_categorical_accuracy=0.3908 lr=5.2920e-04\n",
      "step_run=4800 step_total=4800 step_per_epoch=2909 loss=3.3622 masked_sparse_categorical_accuracy=0.3921 lr=5.2360e-04\n",
      "step_run=4900 step_total=4900 step_per_epoch=2909 loss=3.3369 masked_sparse_categorical_accuracy=0.3935 lr=5.1818e-04\n",
      "step_run=5000 step_total=5000 step_per_epoch=2909 loss=3.3092 masked_sparse_categorical_accuracy=0.3949 lr=5.1291e-04\n",
      "step_run=5100 step_total=5100 step_per_epoch=2909 loss=3.2586 masked_sparse_categorical_accuracy=0.3963 lr=5.0781e-04\n",
      "step_run=5200 step_total=5200 step_per_epoch=2909 loss=3.2401 masked_sparse_categorical_accuracy=0.3978 lr=5.0285e-04\n",
      "INFO:tensorflow:Preparing new records\n",
      "step_run=5300 step_total=5300 step_per_epoch=2909 loss=3.2300 masked_sparse_categorical_accuracy=0.3993 lr=4.9804e-04\n",
      "step_run=5400 step_total=5400 step_per_epoch=2909 loss=2.9878 masked_sparse_categorical_accuracy=0.4011 lr=4.9336e-04\n",
      "step_run=5500 step_total=5500 step_per_epoch=2909 loss=2.9776 masked_sparse_categorical_accuracy=0.4032 lr=4.8882e-04\n",
      "step_run=5600 step_total=5600 step_per_epoch=2909 loss=2.9559 masked_sparse_categorical_accuracy=0.4053 lr=4.8439e-04\n",
      "step_run=5700 step_total=5700 step_per_epoch=2909 loss=2.9672 masked_sparse_categorical_accuracy=0.4072 lr=4.8009e-04\n",
      "step_run=5800 step_total=5800 step_per_epoch=2909 loss=2.9451 masked_sparse_categorical_accuracy=0.4091 lr=4.7589e-04\n",
      "296/296 [==============================] - 45s 151ms/step - loss: 3.0506 - masked_sparse_categorical_accuracy: 0.4561\n",
      "step_run=5900 step_total=5900 step_per_epoch=2909 loss=2.9432 masked_sparse_categorical_accuracy=0.4518 lr=4.7181e-04\n",
      "step_run=6000 step_total=6000 step_per_epoch=2909 loss=2.9230 masked_sparse_categorical_accuracy=0.4630 lr=4.6782e-04\n",
      "step_run=6100 step_total=6100 step_per_epoch=2909 loss=2.9245 masked_sparse_categorical_accuracy=0.4648 lr=4.6394e-04\n",
      "step_run=6200 step_total=6200 step_per_epoch=2909 loss=2.9088 masked_sparse_categorical_accuracy=0.4653 lr=4.6015e-04\n",
      "step_run=6300 step_total=6300 step_per_epoch=2909 loss=2.9172 masked_sparse_categorical_accuracy=0.4653 lr=4.5646e-04\n",
      "step_run=6400 step_total=6400 step_per_epoch=2909 loss=2.8805 masked_sparse_categorical_accuracy=0.4658 lr=4.5285e-04\n",
      "step_run=6500 step_total=6500 step_per_epoch=2909 loss=2.9057 masked_sparse_categorical_accuracy=0.4666 lr=4.4932e-04\n",
      "step_run=6600 step_total=6600 step_per_epoch=2909 loss=2.8900 masked_sparse_categorical_accuracy=0.4667 lr=4.4588e-04\n",
      "step_run=6700 step_total=6700 step_per_epoch=2909 loss=2.8482 masked_sparse_categorical_accuracy=0.4675 lr=4.4251e-04\n",
      "step_run=6800 step_total=6800 step_per_epoch=2909 loss=2.8270 masked_sparse_categorical_accuracy=0.4686 lr=4.3922e-04\n",
      "step_run=6900 step_total=6900 step_per_epoch=2909 loss=2.8409 masked_sparse_categorical_accuracy=0.4695 lr=4.3601e-04\n",
      "step_run=7000 step_total=7000 step_per_epoch=2909 loss=2.8242 masked_sparse_categorical_accuracy=0.4702 lr=4.3286e-04\n",
      "step_run=7100 step_total=7100 step_per_epoch=2909 loss=2.8256 masked_sparse_categorical_accuracy=0.4709 lr=4.2978e-04\n",
      "step_run=7200 step_total=7200 step_per_epoch=2909 loss=2.8056 masked_sparse_categorical_accuracy=0.4717 lr=4.2676e-04\n",
      "step_run=7300 step_total=7300 step_per_epoch=2909 loss=2.7982 masked_sparse_categorical_accuracy=0.4724 lr=4.2381e-04\n",
      "step_run=7400 step_total=7400 step_per_epoch=2909 loss=2.7825 masked_sparse_categorical_accuracy=0.4731 lr=4.2091e-04\n",
      "step_run=7500 step_total=7500 step_per_epoch=2909 loss=2.8037 masked_sparse_categorical_accuracy=0.4738 lr=4.1808e-04\n",
      "step_run=7600 step_total=7600 step_per_epoch=2909 loss=2.7573 masked_sparse_categorical_accuracy=0.4744 lr=4.1530e-04\n",
      "step_run=7700 step_total=7700 step_per_epoch=2909 loss=2.7725 masked_sparse_categorical_accuracy=0.4751 lr=4.1258e-04\n",
      "step_run=7800 step_total=7800 step_per_epoch=2909 loss=2.7363 masked_sparse_categorical_accuracy=0.4758 lr=4.0991e-04\n",
      "step_run=7900 step_total=7900 step_per_epoch=2909 loss=2.7447 masked_sparse_categorical_accuracy=0.4765 lr=4.0729e-04\n",
      "INFO:tensorflow:Preparing new records\n",
      "step_run=8000 step_total=8000 step_per_epoch=2909 loss=2.5765 masked_sparse_categorical_accuracy=0.4774 lr=4.0472e-04\n",
      "step_run=8100 step_total=8100 step_per_epoch=2909 loss=2.4356 masked_sparse_categorical_accuracy=0.4793 lr=4.0220e-04\n",
      "step_run=8200 step_total=8200 step_per_epoch=2909 loss=2.4401 masked_sparse_categorical_accuracy=0.4813 lr=3.9972e-04\n",
      "step_run=8300 step_total=8300 step_per_epoch=2909 loss=2.4494 masked_sparse_categorical_accuracy=0.4830 lr=3.9729e-04\n",
      "step_run=8400 step_total=8400 step_per_epoch=2909 loss=2.4857 masked_sparse_categorical_accuracy=0.4845 lr=3.9490e-04\n",
      "step_run=8500 step_total=8500 step_per_epoch=2909 loss=2.4768 masked_sparse_categorical_accuracy=0.4859 lr=3.9256e-04\n",
      "step_run=8600 step_total=8600 step_per_epoch=2909 loss=2.4794 masked_sparse_categorical_accuracy=0.4871 lr=3.9026e-04\n",
      "step_run=8700 step_total=8700 step_per_epoch=2909 loss=2.4649 masked_sparse_categorical_accuracy=0.4883 lr=3.8799e-04\n",
      "296/296 [==============================] - 44s 150ms/step - loss: 2.6515 - masked_sparse_categorical_accuracy: 0.5093\n",
      "step_run=8800 step_total=8800 step_per_epoch=2909 loss=2.4337 masked_sparse_categorical_accuracy=0.5192 lr=3.8577e-04\n",
      "step_run=8900 step_total=8900 step_per_epoch=2909 loss=2.4698 masked_sparse_categorical_accuracy=0.5259 lr=3.8359e-04\n",
      "step_run=9000 step_total=9000 step_per_epoch=2909 loss=2.4550 masked_sparse_categorical_accuracy=0.5242 lr=3.8144e-04\n",
      "step_run=9100 step_total=9100 step_per_epoch=2909 loss=2.4841 masked_sparse_categorical_accuracy=0.5239 lr=3.7932e-04\n",
      "step_run=9200 step_total=9200 step_per_epoch=2909 loss=2.4763 masked_sparse_categorical_accuracy=0.5230 lr=3.7724e-04\n",
      "step_run=9300 step_total=9300 step_per_epoch=2909 loss=2.4698 masked_sparse_categorical_accuracy=0.5230 lr=3.7520e-04\n",
      "step_run=9400 step_total=9400 step_per_epoch=2909 loss=2.4803 masked_sparse_categorical_accuracy=0.5230 lr=3.7319e-04\n",
      "step_run=9500 step_total=9500 step_per_epoch=2909 loss=2.4596 masked_sparse_categorical_accuracy=0.5230 lr=3.7121e-04\n",
      "step_run=9600 step_total=9600 step_per_epoch=2909 loss=2.4745 masked_sparse_categorical_accuracy=0.5229 lr=3.6926e-04\n",
      "step_run=9700 step_total=9700 step_per_epoch=2909 loss=2.4622 masked_sparse_categorical_accuracy=0.5229 lr=3.6734e-04\n",
      "step_run=9800 step_total=9800 step_per_epoch=2909 loss=2.4321 masked_sparse_categorical_accuracy=0.5231 lr=3.6545e-04\n",
      "step_run=9900 step_total=9900 step_per_epoch=2909 loss=2.4327 masked_sparse_categorical_accuracy=0.5236 lr=3.6359e-04\n",
      "step_run=10000 step_total=10000 step_per_epoch=2909 loss=2.4634 masked_sparse_categorical_accuracy=0.5238 lr=3.6176e-04\n",
      "step_run=10100 step_total=10100 step_per_epoch=2909 loss=2.4412 masked_sparse_categorical_accuracy=0.5241 lr=3.5996e-04\n",
      "step_run=10200 step_total=10200 step_per_epoch=2909 loss=2.4375 masked_sparse_categorical_accuracy=0.5244 lr=3.5818e-04\n",
      "step_run=10300 step_total=10300 step_per_epoch=2909 loss=2.4297 masked_sparse_categorical_accuracy=0.5245 lr=3.5643e-04\n",
      "step_run=10400 step_total=10400 step_per_epoch=2909 loss=2.4432 masked_sparse_categorical_accuracy=0.5248 lr=3.5470e-04\n",
      "step_run=10500 step_total=10500 step_per_epoch=2909 loss=2.4217 masked_sparse_categorical_accuracy=0.5251 lr=3.5300e-04\n",
      "INFO:tensorflow:Preparing new records\n",
      "step_run=10600 step_total=10600 step_per_epoch=2909 loss=2.4330 masked_sparse_categorical_accuracy=0.5253 lr=3.5132e-04\n",
      "step_run=10700 step_total=10700 step_per_epoch=2909 loss=2.1362 masked_sparse_categorical_accuracy=0.5264 lr=3.4967e-04\n",
      "step_run=10800 step_total=10800 step_per_epoch=2909 loss=2.1241 masked_sparse_categorical_accuracy=0.5285 lr=3.4804e-04\n",
      "step_run=10900 step_total=10900 step_per_epoch=2909 loss=2.1403 masked_sparse_categorical_accuracy=0.5302 lr=3.4643e-04\n",
      "step_run=11000 step_total=11000 step_per_epoch=2909 loss=2.1482 masked_sparse_categorical_accuracy=0.5318 lr=3.4484e-04\n",
      "step_run=11100 step_total=11100 step_per_epoch=2909 loss=2.1646 masked_sparse_categorical_accuracy=0.5331 lr=3.4328e-04\n",
      "step_run=11200 step_total=11200 step_per_epoch=2909 loss=2.1848 masked_sparse_categorical_accuracy=0.5343 lr=3.4174e-04\n",
      "step_run=11300 step_total=11300 step_per_epoch=2909 loss=2.1917 masked_sparse_categorical_accuracy=0.5352 lr=3.4022e-04\n",
      "step_run=11400 step_total=11400 step_per_epoch=2909 loss=2.1771 masked_sparse_categorical_accuracy=0.5361 lr=3.3871e-04\n",
      "step_run=11500 step_total=11500 step_per_epoch=2909 loss=2.2047 masked_sparse_categorical_accuracy=0.5370 lr=3.3723e-04\n",
      "step_run=11600 step_total=11600 step_per_epoch=2909 loss=2.1996 masked_sparse_categorical_accuracy=0.5378 lr=3.3577e-04\n",
      "296/296 [==============================] - 44s 150ms/step - loss: 2.4733 - masked_sparse_categorical_accuracy: 0.5345\n",
      "step_run=11700 step_total=11700 step_per_epoch=2909 loss=2.2133 masked_sparse_categorical_accuracy=0.5465 lr=3.3432e-04\n",
      "step_run=11800 step_total=11800 step_per_epoch=2909 loss=2.2032 masked_sparse_categorical_accuracy=0.5558 lr=3.3290e-04\n",
      "step_run=11900 step_total=11900 step_per_epoch=2909 loss=2.2012 masked_sparse_categorical_accuracy=0.5570 lr=3.3149e-04\n",
      "step_run=12000 step_total=12000 step_per_epoch=2909 loss=2.1970 masked_sparse_categorical_accuracy=0.5575 lr=3.3010e-04\n",
      "step_run=12100 step_total=12100 step_per_epoch=2909 loss=2.2223 masked_sparse_categorical_accuracy=0.5575 lr=3.2873e-04\n",
      "step_run=12200 step_total=12200 step_per_epoch=2909 loss=2.2044 masked_sparse_categorical_accuracy=0.5576 lr=3.2737e-04\n",
      "step_run=12300 step_total=12300 step_per_epoch=2909 loss=2.2188 masked_sparse_categorical_accuracy=0.5574 lr=3.2603e-04\n",
      "step_run=12400 step_total=12400 step_per_epoch=2909 loss=2.2015 masked_sparse_categorical_accuracy=0.5574 lr=3.2471e-04\n",
      "step_run=12500 step_total=12500 step_per_epoch=2909 loss=2.2238 masked_sparse_categorical_accuracy=0.5574 lr=3.2340e-04\n",
      "step_run=12600 step_total=12600 step_per_epoch=2909 loss=2.2276 masked_sparse_categorical_accuracy=0.5573 lr=3.2211e-04\n",
      "step_run=12700 step_total=12700 step_per_epoch=2909 loss=2.2211 masked_sparse_categorical_accuracy=0.5573 lr=3.2084e-04\n",
      "step_run=12800 step_total=12800 step_per_epoch=2909 loss=2.2121 masked_sparse_categorical_accuracy=0.5574 lr=3.1958e-04\n",
      "step_run=12900 step_total=12900 step_per_epoch=2909 loss=2.2397 masked_sparse_categorical_accuracy=0.5572 lr=3.1833e-04\n",
      "step_run=13000 step_total=13000 step_per_epoch=2909 loss=2.1957 masked_sparse_categorical_accuracy=0.5572 lr=3.1710e-04\n",
      "step_run=13100 step_total=13100 step_per_epoch=2909 loss=2.2117 masked_sparse_categorical_accuracy=0.5575 lr=3.1588e-04\n",
      "step_run=13200 step_total=13200 step_per_epoch=2909 loss=2.2092 masked_sparse_categorical_accuracy=0.5576 lr=3.1468e-04\n",
      "INFO:tensorflow:Preparing new records\n",
      "step_run=13300 step_total=13300 step_per_epoch=2909 loss=2.0942 masked_sparse_categorical_accuracy=0.5578 lr=3.1349e-04\n",
      "step_run=13400 step_total=13400 step_per_epoch=2909 loss=1.8964 masked_sparse_categorical_accuracy=0.5599 lr=3.1231e-04\n",
      "step_run=13500 step_total=13500 step_per_epoch=2909 loss=1.9323 masked_sparse_categorical_accuracy=0.5620 lr=3.1115e-04\n",
      "step_run=13600 step_total=13600 step_per_epoch=2909 loss=1.9322 masked_sparse_categorical_accuracy=0.5638 lr=3.1000e-04\n",
      "step_run=13700 step_total=13700 step_per_epoch=2909 loss=1.9594 masked_sparse_categorical_accuracy=0.5653 lr=3.0886e-04\n",
      "step_run=13800 step_total=13800 step_per_epoch=2909 loss=1.9585 masked_sparse_categorical_accuracy=0.5666 lr=3.0773e-04\n",
      "step_run=13900 step_total=13900 step_per_epoch=2909 loss=1.9826 masked_sparse_categorical_accuracy=0.5676 lr=3.0662e-04\n",
      "step_run=14000 step_total=14000 step_per_epoch=2909 loss=1.9508 masked_sparse_categorical_accuracy=0.5686 lr=3.0552e-04\n",
      "step_run=14100 step_total=14100 step_per_epoch=2909 loss=1.9941 masked_sparse_categorical_accuracy=0.5695 lr=3.0443e-04\n",
      "step_run=14200 step_total=14200 step_per_epoch=2909 loss=1.9796 masked_sparse_categorical_accuracy=0.5702 lr=3.0335e-04\n",
      "step_run=14300 step_total=14300 step_per_epoch=2909 loss=1.9968 masked_sparse_categorical_accuracy=0.5709 lr=3.0229e-04\n",
      "step_run=14400 step_total=14400 step_per_epoch=2909 loss=2.0018 masked_sparse_categorical_accuracy=0.5715 lr=3.0123e-04\n",
      "step_run=14500 step_total=14500 step_per_epoch=2909 loss=2.0007 masked_sparse_categorical_accuracy=0.5720 lr=3.0019e-04\n",
      "296/296 [==============================] - 44s 149ms/step - loss: 2.3841 - masked_sparse_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00005: saving model to /content/drive/My Drive/transformer_model/model.05.hdf5\n",
      "INFO:tensorflow:Copying TPU weights to the CPU\n",
      "INFO:tensorflow:TPU -> CPU lr: 0.00029921092209406197\n",
      "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
      "INFO:tensorflow:TPU -> CPU beta_2: 0.9800000190734863\n",
      "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
      "INFO:tensorflow:TPU -> CPU epsilon: 1e-08\n",
      "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
      "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
      "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
      "INFO:tensorflow:Elapsed_time=6482.618\n"
     ]
    }
   ],
   "source": [
    "# Configure and start fitting\n",
    "env = FitEnvironment(\n",
    "        use_tpu=True,\n",
    "        batch_size=8,\n",
    "        input_len=(1024, 1024),\n",
    "        num_epoch=5,\n",
    "        output_dir='/content/drive/My Drive/transformer_model',\n",
    "        data_path=['data/kyoto_en_ja.csv'],\n",
    "        valid_path=['data/kyoto_en_ja_valid.csv'],\n",
    "        resume_model_path=None,\n",
    "        resume_initial_epoch=None,\n",
    "    )\n",
    "# run (training 5 epoch with 0.5 million samples) will take a time.\n",
    "# The summary of my case:\n",
    "# Total elapsed time: 6483 s\n",
    "#    - before starting fit_generator method: 119 s\n",
    "#    - compilation of model on TPU for train mode: 151 s\n",
    "#    - re-compilation for eval mode: 68 s\n",
    "#    - the other computation: 6145 s\n",
    "# (I think 5 epochs is not enough for convergence)\n",
    "wrapper = env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTWyh2X_HEmX"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# We will make a loaded model run on CPU \n",
    "# because TPU requires batch size can be devided by the number of devices (8).\n",
    "# Clear TPU configuration left in the current thread before creating them. \n",
    "tf.keras.backend.clear_session()\n",
    "from src.transformer import TransformerWrapper\n",
    "trans = TransformerWrapper('/content/drive/My Drive/transformer_model/model.05.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z60fzOv-J5wF",
    "outputId": "07262a07-9fd2-4b85-ba11-8c43378b0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'京都(きょうと)は、日本の市。'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans('Kyoto is a Japanese city.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "caNyxFiuQh_Y",
    "outputId": "d492ec85-0d75-4217-fd5b-4fb9d65e0eda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'平清盛像を安置し、経巻を施す。'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans('A statue of a Buddhist monk, taken to be TAIRA no Kiyomori, holding scriptures.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S3WN984aRAj0",
    "outputId": "311a1f50-b71b-4689-b278-3f8b72f1b4ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'「本願寺勢力」という表現は、現在の浄土真宗本願寺派と混同され、現在の本願寺派と混同されている。'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans(\"The expression 'Hongan-ji Temple power' is used here because 'Hongan-ji Temple school' would be confused with the current Jodo Shinshu Hongan-ji school (Nishi Hongan-ji Temple school).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArkQU_FeRL8I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "tf-keras-transformer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
